---
title: "AEF Exam"
author: "48, 49, 57"
date: "7/5/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  echo = FALSE,
  fig.align = "center",
  warning = FALSE,
  message = FALSE,
  out.width = ".65\\linewidth"
)

########################
### BEGIN USER INPUT ###
######################## 

# Automatic setup for working directory for authors of this file
tmp <- getwd()
if(substr(tmp,1,12) == "C:/Users/Mie"){
  # Mie
  setwd("C:/Users/Mie/OneDrive/CBS/Kandidat/data")
} else if(substr(tmp,1,14) == "C:/Users/Alexm"){
  # Alexander
  setwd("C:/Users/Alexm/Documents")
} else{
  # Philip
  setwd("C:/Users/phili/OneDrive - CBS - Copenhagen Business School/Desktop/Code/R - code/AEF")
}

# If NON-AUTHOR runs this code, please insert your own path to the working directory where you store tidy_finance.sqlite and uncomment the line below:
# setwd("INSERT PATH TO YOUR TIDY_FINANCE FILE")


# The following input is used in part 2 of the exam
gamma_default <- 4

######################
### END USER INPUT ###
######################


# Loading packages
library(tidyquant)
library(tidyverse)
library(RSQLite)
library(lubridate)
library(sandwich)
library(lmtest)
library(scales)
library(kableExtra)


# Changes decimals from having e to having 0s
options(scipen = 999)

# Loading relevant data for part 1 of the exam
tidy_finance <- dbConnect(SQLite(), "tidy_finance.sqlite", extended_types = TRUE) # Connect to sql

crsp_monthly <- tbl(tidy_finance, "crsp_monthly") %>% collect() %>% select("permno", "month", "ret_excess", "mktcap",                                                                                     "mktcap_lag")

ff_monthly <- tbl(tidy_finance, "factors_ff_monthly") %>% collect() %>% select("month", "mkt_excess")


# Loading relevant data for part 2 of the exam
US_Stocks <- read.csv(file = "data_exam2022.csv")

```

# Exam part 1



## Excercise 1
The financial stock data for this assignment comes from the CRSP-universe and includes stock data from "1989-02-01" to "2020-12-01). We load the variables *permno*, *month*, *ret_excess*, *mktcap* and *mktcap_lag*. Furthermore, we also use the monthly Fama-French data which includes the variables *month* and *mkt_excess*. Below is the definition of the variables used in the assignment:
1. *Permno*: Permno is a security identification number. Each security has its own unique PERMNO. A permno belongs to permco and a permco is CRPS's company identifier. One permco is not locked to only one permno, but can have more than one. 
2. *ret_excess*: This is the excess return, which is the return on the stock minus the return we get on the risk-free asset over the same period. So the excess return shows the extra return you get by investing in a risky asset compared to just putting your money in the bank (investing in the risk-free asset).
3. *mktcap*: Market capitalization (or market cap) is the total value of the company. It is calculated as the total amount of outstanding shares of a company multiplied with the stock price. This makes it easier to compare the size of each company to one another and to the market in general. 
4. *mkt_excess*: This is the excess return for the whole market combined.

In order to get a sense of the data, we create the following summary statistics, where we calculate the mean, standard deviation and quartiles for both the excess return and the market capitalization for each month and then we average these results over all months. This gives us the following table:

```{r summary statistics, echo=FALSE}

# Creating the summary statistics of the excess return and market cap
 crsp_monthly_reduced <- crsp_monthly %>% select(ret_excess, mktcap)
# 
# kable(summary(crsp_monthly_reduced), booktabs = T, digits = 4, col.names = c("Excess Return", "Market Cap"), 
#       caption = "Summary statistics of the excess return and the market cap") %>% 
#   kable_classic(full_width = F) %>% 
#   kable_styling(latex_options = "HOLD_position")




# Generates an empty data frame, assigns columns for summary statistics and loads a vector with the variables we wish to summarise
summary1 <- data.frame(matrix(ncol=7, nrow=2)) #There are 7 summary statistics and two variables
colnames(summary1) <- c("mean", "sd", "min", "Q1","median", "Q3", "max")
var_names <- c("ret_excess",  "mktcap")

# Loops through all the chosen variables and calculates mean, sd, min, Q1, median, Q3 and max for each month then takes the average of those results.  
for(i in 1:2){  
              summary1[i,] <- crsp_monthly %>%
                              group_by(month) %>%
                              summarise(across(var_names[i],
                                        list(mean = mean, 
                                             sd = sd, 
                                             min = min,
                                             q25 = ~quantile(., 0.25),
                                             median = median,
                                             q75 = ~quantile(., 0.75), 
                                             max = max),
                                        .names = "{.fn}  ")
                                        ) %>%
                              summarise(across(-month, mean))
              }

#Assigns relevant row names
rownames(summary1) <- c("Excess return", "Market cap")

# Rounding the excess return values to 4 for the output
summary1[1,] <- round(summary1[1,], 4)

# Rounding the market cap values (since they are so large that decimals have no real significance)
summary1[2,c(1:2, 4:7)] <- round(summary1[2,c(1:2, 4:7)], 0)

#Prints the summary nicely in a table
summary1 %>% knitr::kable(booktabs = T, digits = 4, caption = "Summary statistics of the excess return and the market cap") %>%              kable_paper("hover", full_width = T) %>% 
             kable_styling(latex_options = "HOLD_position")

```

Table 1 shows that the cross-section mean of the excess return and market capitalization is 0.0083 and 1815, respectively. On average the monthly excess return varies from -0.6906 to 2.6775 where the market capitalization on average varies from 0.7 to 242415. Furthermore, it is seen that the mean is larger than the median for both variables. This indicates that the distribution of the data is positively skewed (right-skewed). 


## Excercise 1

The reason why *crsp_monthly %>% group_by(permno) %>% mutate(ret_excess_lag = lag(ret_excess))* does not provide the correct result if there are non-explicit missing values in the time series is, that the lag function doesn't differentiate between one-month lag and just the closest lag available. If data for a specific month, lets say May, doesn't exist, then it just takes April as the lagged value instead, which would be wrong. Therefore, a better way to find the lagged excess return would be to copy the data to a new data frame (only including permno, month and excess return) where you overwrite the month to be the next month. This means that all the data in the new data frame is now depicted as being one month ahead of what it actually is. Then you re-name the excess return column to instead depict lagged excess return and lastly you drop all the NAs in the data frame. By now innerjoining this data frame to the original on month and permno you now get the lagged excess return variable as well.


```{r summerise for autocorrelation, echo=FALSE}

# Creating a new table where the month in crsp_monthly is moved 1 month ahead and then the excess return is renamed to ret_excess_lag and na dropped
crsp_monthly_month_changed <- crsp_monthly %>% 
                              mutate(month = month %m+% months(1)) %>% 
                              select(permno, month, ret_excess_lag = ret_excess) %>% 
                              drop_na()

# Using inner join on month and permno to add ret_excess_lag and only keep complete data where there is no na
crsp_monthly_new <- crsp_monthly %>% 
                    inner_join(crsp_monthly_month_changed, by = c("permno", "month"))

return_correlation <- cor(crsp_monthly_new$ret_excess,crsp_monthly_new$ret_excess_lag)

```
In order to investigate whether or not the returns exhibit autocorrelation of lag 1, then we can find the correlation between the excess return and the lagged excess return, which is: `r round(return_correlation, 4)`. This negative correlation implies that the returns move in opposite direction from the lagged returns. Therefore, if the returns have been positive last month, then they are likely to be negative this month and vice versa. 


## Excercise 1.3
We start by adding a new column showing the momentum of a company. The momentum is calculated as the growth of the market capitalization for a company over the past year. The market cap 12 with 12 months lag is calculated in the same way as described in excercise 2 with the lagged excess return:
$$
Mom_{i,t} = 100*\frac{(mc_{i,t-1}-mc_{i,t-12})}{mc_{i,t-12}}
$$
The difference between computing momentum as the relative change in prices or as the relative change in market capitalization is fundamentally identical. However when working with data over long time periods market capitalization has a profound edge over prices. When using prices the momentum will be affected by noise caused by operations in the financial market that has nothing to with the market valuation of the company. The issuing of new stocks will naturally dilute the value of a single stock causing prices to drop, but it will not affect the market capitalization. If a company for example decides to split up the stocks so each stock is made into two, this will cut the price of the stock in half but leave the market capitalization unchanged which promotes the use of market capitalization over prices.

```{r lag for 12 months, echo=FALSE}

# Creating a new table where the month in crsp_monthly is moved 1 month ahead and then the excess return is renamed to ret_excess_lag and na dropped
crsp_monthly_month_changed_12 <- crsp_monthly %>% 
                                 mutate(month = month %m+% months(12)) %>% 
                                 select(permno, month, mktcap_lag_12 = mktcap) %>% 
                                 drop_na()

# Using inner join on month and permno to add ret_excess_lag and only keep complete data where there is no na
crsp_monthly_mom <- crsp_monthly %>% 
                    inner_join(crsp_monthly_month_changed_12, by = c("permno", "month"))

# calculation of mom and add to a new column
crsp_monthly_mom <- crsp_monthly_mom %>% 
                    group_by(permno) %>% 
                    mutate(mom = 100*(mktcap_lag - mktcap_lag_12)/mktcap_lag_12) 

# Generates an empty data frame, assigns columns for summary statistics
summary2 <- data.frame(matrix(ncol=9, nrow=1)) #There are 9 summary statistics and one variable
colnames(summary2) <- c("mean", "sd", "min", "5th", "25th","median", "75th", "95th", "max")

# Calculates mean, sd, min, 5th percentile, 25th percentile, median, 75th percentile, 95th percentile and max for each month and then takes the average of those results.
summary2[1,] <- crsp_monthly_mom %>%
                group_by(month) %>%
                summarise(across(mom,
                                 list(mean = mean, 
                                      sd = sd, 
                                      min = min,
                                      q05 = ~quantile(., 0.05),
                                      q25 = ~quantile(., 0.25),
                                      median = median,
                                      q75 = ~quantile(., 0.75),
                                      q95 = ~quantile(., 0.95),
                                      max = max),
                                 .names = "{.fn}  ")
                          ) %>%
                summarise(across(-month, mean))

#Assigns relevant row names
rownames(summary2) <- "Momentum"

#Prints the summary nicely in a table
summary2 %>% knitr::kable(booktabs = T, digits = 2, caption = "Summary statistics of the momentum") %>% 
             kable_paper("hover", full_width = T) %>% 
             kable_styling(latex_options = "HOLD_position")

mom_mktcap_correlation <- cor(crsp_monthly_mom$mom, log(crsp_monthly_mom$mktcap))

```
Table 2 shows that the cross-section mean of momentum is 19 while the median is only 5.6. Just like in table 1, this indicates a positive skew (right-skew). There are therefore very large momentum values which have a big impact on the mean, which is also seen by the average maximum momentum being 3200. We can also notice that the standard deviation is 96 and therefore quite high (especially when comparing to a mean of 19). Another indication of the effect of the extreme large momentum-values is the difference between the 95th percentile and the maximum. Since the 95th percentile is "only" 118, then this means that only 5% of the observations have a momentum of 118 or larger.

By calculating the correlation between momentum and $log(mc_{i,t})$ we get a value of `r round(mom_mktcap_correlation, 4)`. We therefore see a positive correlation between momentum and $log(mc_{i,t})$. If we can observe positive momentum over the past year, then we can to some degree expect a larger market cap next month.


## Excercise 1
Now we want to examine the relationship between momentum and future stock returns. First we start by dividing the stock into 10 portfolios based on the size of the momentum for a stock given each period. In the following, we have calculated the equal-weighted average values of the momentum and market capitalization for each of the 10 portfolios:

```{r Relation, echo=FALSE}
# Arranges data by month instead of permno
crsp_monthly_mom <- crsp_monthly_mom %>% 
                    arrange(month)

# Calculating the decile breakpoints for the mom for each months and defines which portfolio belongs to each month
mom_portfolios <- crsp_monthly_mom %>%
                  group_by(month) %>%
                  mutate(breakpoint_1 = quantile(mom, probs = .1),
                         breakpoint_2 = quantile(mom, probs = .2),
                         breakpoint_3 = quantile(mom, probs = .3),
                         breakpoint_4 = quantile(mom, probs = .4),
                         breakpoint_5 = quantile(mom, probs = .5),
                         breakpoint_6 = quantile(mom, probs = .6),
                         breakpoint_7 = quantile(mom, probs = .7),
                         breakpoint_8 = quantile(mom, probs = .8),
                         breakpoint_9 = quantile(mom, probs = .9),
                         portfolio = case_when(mom <= breakpoint_1 ~ 1,
                                               mom > breakpoint_1 & mom <= breakpoint_2 ~ 2,
                                               mom > breakpoint_2 & mom <= breakpoint_3 ~ 3,
                                               mom > breakpoint_3 & mom <= breakpoint_4 ~ 4,
                                               mom > breakpoint_4 & mom <= breakpoint_5 ~ 5,
                                               mom > breakpoint_5 & mom <= breakpoint_6 ~ 6,
                                               mom > breakpoint_6 & mom <= breakpoint_7 ~ 7,
                                               mom > breakpoint_7 & mom <= breakpoint_8 ~ 8,
                                               mom > breakpoint_8 & mom <= breakpoint_9 ~ 9,
                                               mom > breakpoint_9 ~ 10
                                               )) %>%
                  select("permno", "month", "ret_excess", "mktcap", "mktcap_lag", "mktcap_lag_12", "mom", "portfolio") %>%
                  mutate(portfolio = as.factor(portfolio))

# Creating table of equal weighted average of momentum and market cap
mom_portfolios %>% group_by(portfolio) %>%
                   summarise('average momentum' = mean(mom),'average market capitalization' = mean(mktcap)) %>%
                   knitr::kable(booktabs = T, digits = 2, col.names = c("Portfolio number", "Average momentum",                                                                                        "Average market capitalization"), 
                                caption = "Equal weighted momentum-sorted portfolios with average momentum and market capitalization for each") %>% 
                   kable_paper("hover", full_width = T) %>% 
                   kable_styling(latex_options = "HOLD_position")

```
In table **MISSING** we see that the momentum is increasing with the portfolio number (which makes sense as per the creation of the portfolios). We also notice that the average market capitalization in increasing from portfolio 1-7 and then begins to fall back down for the last three portfolios with the highest momentum.

We now calculate the value-weighted monthly excess returns for each of the portfolios which is depicted in the table below.

```{r, echo=FALSE}
# Creating monthly portfolio value-weighted excess returns
mom_portfolios <- mom_portfolios %>%
                  group_by(month, portfolio) %>%
                  summarize(ret_excess = weighted.mean(ret_excess, mktcap_lag), .groups = "drop")

# Adds the Fama-French market excess return to the data frame
mom_portfolios <- mom_portfolios %>%
                  left_join(ff_monthly, by = "month")

# Finding the CAPM alpha by regressing the data onto the market excess return
mom_portfolios %>% group_by(portfolio) %>%
                   summarise(alpha = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[1]),
                             beta = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[2]),
                             ret_excess = mean(ret_excess)
                             ) %>%
                   knitr::kable(booktabs = T, digits = 4, col.names = c("Portfolio number", "CAPM alpha", "Market beta",                                                                                "Average value-weighted excess return"), 
                                caption = "CAPM alpha, beta and excess return for the value-weighted momentum-sorted portfolios") %>% 
                   kable_paper("hover", full_width = T) %>% 
                   kable_styling(latex_options = "HOLD_position")

```

In table **MISSING** we see that the average value-weighted returns and the CAPM alphas (risk-adjusted performance) are increasing in the portfolios (with the exception of portfolio 6 and 7). We also see that all of the portfolios are very correlated with the market return which is depicted in the Market beta. Most of the portfolios have a Market beta around 1 which indicates that they move more or less like the market. Portfolio 1 is however extremely correlated with the market returns, so whenever the market moves a little bit in one direction, then this portfolio moves a lot in the same direction, making the fluctuations very large. Since we are interested in looking at the CAPM alphas of the different portfolios, we have depicted them in the graph below, so they are easier to compare to each other.

```{r, echo=FALSE}
mom_portfolios_summary <- mom_portfolios %>%
                          group_by(portfolio) %>%
                          summarise(alpha = summary(lm(ret_excess ~ mkt_excess))$coefficients[1])

# Plot for CAPM alpha
#while (!is.null(dev.list()))  dev.off() # Resets device settings (just in case, as it may cause problems)
mom_portfolios_summary %>% ggplot(aes(x = as.factor(portfolio), y = alpha, fill = as.factor(portfolio))) +
                           geom_bar(stat = "identity") +
                           labs(title = "CAPM alphas of the momentum-sorted portfolios with value-weighted returns",
                                x = "Momentum-sorted portfolios",
                                y = "CAPM alpha",
                                fill = "Portfolio"
                                ) +
                           scale_y_continuous(labels = percent) +
                           theme(legend.position = "None") + 
                           theme_bw()

mean_return <- aggregate(ret_excess~portfolio, data = mom_portfolios, mean)

sharp_ratio_e4 <- mean_return$ret_excess/sd(mom_portfolios$ret_excess) # Not sure about Sharpe Ratio, because they are very small
```

As seen in the graph above, it looks like there is a large negative CAPM alpha for portfolio 1 and  a fairly large positive CAPM alpha for portfolio 10. We therefore try to analyse the momentum strategy where we go long in portfolio 10 (which has the highest momentum) and go short in portfolio 1 (which has the lowest momentum). So for each month we compute the return of this long-short portfolio by taking the value-weighted return for portfolio 10 and subtracting the value-weighted return for portfolio 1. Running a linear regression of the long-short return on the market return gives us the following table. The last row in the table is computed as a t-test to investigate if the true mean of the return could be 0.


```{r, echo=FALSE}
# Creating the returns for the long-short portfolio
long_short_portfolio <- mom_portfolios %>%
                        filter(portfolio %in% c(1, 10)) %>%
                        mutate(portfolio = case_when(portfolio == 10 ~ "high",
                                                     portfolio == 1 ~ "low")
                               ) %>%
                        pivot_wider(month, names_from = portfolio, values_from = ret_excess) %>%
                        mutate(long_short = high - low) %>%
                        left_join(ff_monthly, by = "month")

# Making a linear regression of the portfolio return om the market return in order to get the CAPM values (and then renaming the rows)
long_short_summary <- summary(lm(long_short ~ mkt_excess, data=long_short_portfolio))$coefficients
tmp <- t.test(long_short_portfolio$long_short) # Creating a t.test for the return estimate
long_short_summary <- rbind(long_short_summary, c(tmp$estimate, tmp$stderr, tmp$statistic, tmp$p.value))
row.names(long_short_summary) <- c("CAPM alpha", "Market beta", "Portfolio return")

# Using the linear regression values to depict as a table
long_short_summary %>% knitr::kable(booktabs = T, digits = 4, caption = "CAPM alpha, beta and excess return for the long-short portfolio based on value-weighted momentum-sorted portfolios") %>%
                       kable_paper("hover", full_width = T) %>% 
                       kable_styling(latex_options = "HOLD_position")

# Finding the average return of the long-short portfolio
long_short_return <- mean(long_short_portfolio$long_short)

```

If we start by looking at the bottom row which depict the results for the return, we see that the portfolio does in fact deliver an average return above 0. Wee see this by creating a t-test where the null hypothesis is that the true mean is 0. By looking at the p-value we can reject this on a 5% confidence interval. From the CAPM regression we also see that we get a positive alpha, where we likewise can reject a null hypothesis of the true alpha being 0. By comparing the long-short portfolio alpha with the alphas for portfolio 1 og 10 from table **MISSING** we see that the alpha has now increased. Instead of just going long in portfolio 10, we now get a higher alpha by investing in the long-short portfolio.


## Excercise 1
In the following, we will calculate the CAPM alphas using the k-month-ahead excess returns for $k\in\{1,3,6,12\}$. Since we lose a few observations by having to find the k-months ahead returns, then in order to most efficiently compare all the results, we have chosen to only calculate the CAPM values for observations where we have found all the specific k-months ahead returns. The k-months ahead portfolio returns are calculated as value-weighted returns based on the lagged market cap value (since this is known at the time the portfolio is constructed). It is assumed that the 1-month ahead is just the standard excess return and therefore that 3-months ahead should be calculated as the excess return two months later. The reason for this assumption is that the lagged variables are meant to be known at the time we construct the portfolio, where the excess return is then the result of this. Hence, it must be the 1-month ahead return.

```{r  Repeat the univariate portfolio, echo=FALSE}
# Creating the 3, 6, and 12 months ahead returns by moving back the respective month by 2, 5 or 11 months (since ret_excess is already 1-month ahead) and then adding the fama-french k-month-ahead market return for comparison
excess_return_3_ahead <- crsp_monthly_mom %>% 
                         left_join(ff_monthly, by = "month") %>%
                         mutate(month = month %m+% months(-2)) %>% 
                         select(permno, month, ret_excess_3 = ret_excess, mkt_excess_3 = mkt_excess) %>% 
                         drop_na()

excess_return_6_ahead <- crsp_monthly_mom %>% 
                         left_join(ff_monthly, by = "month") %>%
                         mutate(month = month %m+% months(-5)) %>%
                         select(permno, month, ret_excess_6 = ret_excess, mkt_excess_6 = mkt_excess) %>% 
                         drop_na()

excess_return_12_ahead <- crsp_monthly_mom %>% 
                          left_join(ff_monthly, by = "month") %>%
                          mutate(month = month %m+% months(-11)) %>% 
                          select(permno, month, ret_excess_12 = ret_excess, mkt_excess_12 = mkt_excess) %>% 
                          drop_na()

# Combining all the k-months-ahead returns in one data frame
crsp_monthly_k_months <- crsp_monthly_mom %>%
                         inner_join(excess_return_3_ahead, by = c("permno", "month")) %>%
                         inner_join(excess_return_6_ahead, by = c("permno", "month")) %>%
                         inner_join(excess_return_12_ahead, by = c("permno", "month"))

# Arranges data by month instead of permno
crsp_monthly_k_months <- crsp_monthly_k_months %>% 
                         arrange(month)

# Calculating the decile breakpoints for the mom for each months and defines which portfolio belongs to each month
mom_portfolios_k_ahead <- crsp_monthly_k_months %>%
                          group_by(month) %>%
                          mutate(breakpoint_1 = quantile(mom, probs = .1),
                                 breakpoint_2 = quantile(mom, probs = .2),
                                 breakpoint_3 = quantile(mom, probs = .3),
                                 breakpoint_4 = quantile(mom, probs = .4),
                                 breakpoint_5 = quantile(mom, probs = .5),
                                 breakpoint_6 = quantile(mom, probs = .6),
                                 breakpoint_7 = quantile(mom, probs = .7),
                                 breakpoint_8 = quantile(mom, probs = .8),
                                 breakpoint_9 = quantile(mom, probs = .9),
                                 portfolio = case_when(mom <= breakpoint_1 ~ 1,
                                                       mom > breakpoint_1 & mom <= breakpoint_2 ~ 2,
                                                       mom > breakpoint_2 & mom <= breakpoint_3 ~ 3,
                                                       mom > breakpoint_3 & mom <= breakpoint_4 ~ 4,
                                                       mom > breakpoint_4 & mom <= breakpoint_5 ~ 5,
                                                       mom > breakpoint_5 & mom <= breakpoint_6 ~ 6,
                                                       mom > breakpoint_6 & mom <= breakpoint_7 ~ 7,
                                                       mom > breakpoint_7 & mom <= breakpoint_8 ~ 8,
                                                       mom > breakpoint_8 & mom <= breakpoint_9 ~ 9,
                                                       mom > breakpoint_9 ~ 10
                                )) %>%
                          select("permno", "month", "ret_excess", "ret_excess_3", "ret_excess_6", "ret_excess_12", "mktcap",                                    "mktcap_lag", "mktcap_lag_12", "mom", "portfolio") %>%
                          mutate(portfolio = as.factor(portfolio))

# Creating monthly portfolio value-weighted excess returns
mom_portfolios_k_ahead <- mom_portfolios_k_ahead %>%
                          group_by(month, portfolio) %>%
                          summarise(ret_excess = weighted.mean(ret_excess, mktcap_lag),
                                    ret_excess_3 = weighted.mean(ret_excess_3, mktcap_lag),
                                    ret_excess_6 = weighted.mean(ret_excess_6, mktcap_lag),
                                    ret_excess_12 = weighted.mean(ret_excess_12, mktcap_lag),
                                    .groups = "drop")

# Adds the Fama-French k-months-ahead market excess return to the data frame
excess_return_3_ahead <- excess_return_3_ahead %>% ungroup() %>% select(month, mkt_excess_3) %>% unique()
excess_return_6_ahead <- excess_return_6_ahead %>% ungroup() %>% select(month, mkt_excess_6) %>% unique()
excess_return_12_ahead <- excess_return_12_ahead %>% ungroup() %>% select(month, mkt_excess_12) %>% unique()
mom_portfolios_k_ahead <- mom_portfolios_k_ahead %>%
                          left_join(ff_monthly, by = "month") %>%
                          left_join(excess_return_3_ahead, by = "month") %>%
                          left_join(excess_return_6_ahead, by = "month") %>%
                          left_join(excess_return_12_ahead, by = "month")

# Finding the CAPM alpha by regressing the data onto the market excess return
k_months_ahead_alphas <- mom_portfolios_k_ahead %>%
                         group_by(portfolio) %>%
                         summarise(alpha_1 = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[1]),
                                   alpha_3 = as.numeric(lm(ret_excess_3 ~ mkt_excess_3)$coefficients[1]),
                                   alpha_6 = as.numeric(lm(ret_excess_6 ~ mkt_excess_6)$coefficients[1]),
                                   alpha_12 = as.numeric(lm(ret_excess_12 ~ mkt_excess_12)$coefficients[1])
                                   )
                         k_months_ahead_alphas %>%
                         knitr::kable(booktabs = T, digits = 4, col.names = c("Portfolio number", "Alpha 1 month ahead",                                                                                     "Alpha 3 months ahead", "Alpha 6 months ahead",                                                                                "Alpha 12 months ahead"), 
                                      caption = "CAPM alphas for the value-weighted momentum-sorted portfolios") %>%
                         kable_paper("hover", full_width = T) %>% 
                         kable_styling(latex_options = "HOLD_position")


```

The graph below shows the CAPM alphas for all the k-months-ahead returns (with $k=1,3,6,12$) for all 10 momentum-sorted portfolios. Something that is very noticeable is that the CAPM alpha for the 12-months-ahead returns has opposite signs for most of the portfolios. For portfolio 1 it shows a positive CAPM alpha, where the shorter returns show a negative alpha. As we move into the middle portfolios then the alpha value becomes smaller for all the k-months-ahead returns. According to this investigation, portfolio 1 with a time horizon of 12 months seems to predict the highest risk-adjusted performance. This horizon also continues to deliver positive CAPM alphas for all portfolios except portfolio 9 and 10. However, by looking at the 3-months-ahead CAPM alphas, then we see the same movements as for the original 1-month-ahead just larger. It could therefore suggest that creating the long-short portfolio as we did in exercise 4 would result in an even larger risk-adjusted performance.

```{r, echo=FALSE}

# Creating a tall table with all k-months-ahead alphas together in order to create combined plot
k_months_ahead_alphas_tall <- k_months_ahead_alphas %>% 
                              gather(key = alphas, value = Value, alpha_1:alpha_12) %>%
                              # Below is used alpha1, alpha2, alpha3, alpha4 so that they have the right order in the plot
                              mutate(alphas = case_when(alphas == "alpha_1" ~ "Alpha1",
                                                        alphas == "alpha_3" ~ "Alpha2",
                                                        alphas == "alpha_6" ~ "Alpha3",
                                                        alphas == "alpha_12" ~ "Alpha4",
                                                        ))

# Plot for CAPM alphas
#while (!is.null(dev.list()))  dev.off() # Resets device settings (just in case, as it may cause problems)
k_months_ahead_alphas_tall %>% ggplot(aes(x = as.factor(portfolio), y = Value, fill = alphas)) +
                               geom_col(position = "dodge") +
                               labs(title = "CAPM alphas of the momentum-sorted portfolios with the k-months-ahead returns",
                                    x = "Momentum-sorted portfolios",
                                    y = "CAPM alpha",
                                    fill = "Portfolio"
                                    ) +
                               scale_fill_discrete(labels = c("1-month-ahead", "3-months-ahead", "6-months-ahead",                                                                           "12-months-ahead")) +
                               scale_y_continuous(labels = percent) +
                               theme_bw() +
                               theme(legend.position = "bottom") + 
                               theme(plot.title = element_text(size=10))

```


## Excercise 1

```{r Finding from 1 and 3, echo=FALSE}
unique_months <- unique(crsp_monthly_mom$month)
half_months <- unique_months[seq(1, length(unique_months), 2)] # In order to delete every other month

mom_portfolios <- crsp_monthly_mom %>%
                  group_by(month) %>%
                  mutate(breakpoint_10 = quantile(mom, probs = .1),
                         breakpoint_20 = quantile(mom, probs = .2),
                         breakpoint_30 = quantile(mom, probs = .3),
                         breakpoint_40 = quantile(mom, probs = .4),
                         breakpoint_50 = quantile(mom, probs = .5),
                         breakpoint_60 = quantile(mom, probs = .6),
                         breakpoint_70 = quantile(mom, probs = .7),
                         breakpoint_80 = quantile(mom, probs = .8),
                         breakpoint_90 = quantile(mom, probs = .9),
                         portfolio = case_when(mom <= breakpoint_10 ~ 10,
                                               mom > breakpoint_10 & mom <= breakpoint_20 ~ 20,
                                               mom > breakpoint_20 & mom <= breakpoint_30 ~ 30,
                                               mom > breakpoint_30 & mom <= breakpoint_40 ~ 40,
                                               mom > breakpoint_40 & mom <= breakpoint_50 ~ 50,
                                               mom > breakpoint_50 & mom <= breakpoint_60 ~ 60,
                                               mom > breakpoint_60 & mom <= breakpoint_70 ~ 70,
                                               mom > breakpoint_70 & mom <= breakpoint_80 ~ 80,
                                               mom > breakpoint_80 & mom <= breakpoint_90 ~ 90,
                                               mom > breakpoint_90 ~ 100
                         )) %>%
              # stores the excess return for the next periode, so it is not forgotten when that period is deleted
               mutate(ret_excess_lead = lead(ret_excess)) %>% 
               filter(month %in% half_months) %>% # Deleting every other month so we dont rebalance during these months
               filter(!is.na(ret_excess_lead)) %>%
               mutate(ret_excess_sum = ret_excess + ret_excess_lead) %>%
               group_by(month, portfolio) %>%
               summarize(ret_excess = weighted.mean(ret_excess_sum, mktcap_lag), .groups = "drop")

mom_portfolios <- mom_portfolios %>% left_join(ff_monthly, by = "month")

# Finding CAPM alpha
mom_portfolios_summary <- mom_portfolios %>%
                          group_by(portfolio) %>%
  summarise(alpha = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[1]),
            beta = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[2]),
            ret_excess = mean(ret_excess)
            )

mom_portfolios_summary %>% ggplot(aes(x = portfolio, y = alpha/2, fill = as.factor(portfolio))) +
                           geom_bar(stat = "identity") +
                           labs(title = "Alphas of momentum-sorted portfolios (rebalancing every 2 months)",
                                x = "Momentum decile portfolios",
                                y = "CAPM alpha",
                                fill = "Portfolio"
                                ) +
                           scale_y_continuous(labels = percent) +
                           theme(legend.position = "None")

mean_return1 <- aggregate(ret_excess ~ portfolio, data = mom_portfolios, mean)

sharp_ratio_e6 <- mean_return1$ret_excess/sd(mom_portfolios$ret_excess) # Not sure about Sharpe Ratio, because they are very small

sharp_ratio <- cbind(sharp_ratio_e4,sharp_ratio_e6)

sharp_ratio %>% knitr::kable(digits = 4) #creates a table to view the data.

```

Causes for high trading cost:

 - The portfolio created by the strategy changes often and drastically leading to an almost complete rebuild of the portfolio each time.
 - The strategy has no regard for the liquidity of the assets. It can become costly if you have to buy and sell a not frequently traded asset often.
 

This might be a little far fetched but most studies also assume assets to be completely divisible. This is obviously not the case in the real world and the strategy therefore requires a large amount of capital to be implemented.


A way to lower trading cost would be to reduce the turnover by imposing a restriction on the holding period. This would mean that when the strategy buys an asset it must be held for at least x amount of time.


We suggest a strategy where the assets are held for 2 months instead of 1. This should cause a noticeable drop in trading cost due to lower turnover.



# Exam part 2
In part 2 of this report we will use a dataset which consists of 252 monthly observations for $N=8$ different US-listed stocks identified by their permno which is a unique company identifier. The permno for the stocks used are: 10026, 10032, 10044, 10104, 10200, 10232, 10252 and 10397. The whole dataset includes monthly observations from "2000-01-01" to "2020-12-01". The first two problems will focus on the data up until (and including) 2015, where problem 3 will then use the last 5 years in order to test the **MISSING** estimated in problem 1 and 2. For each month-permno observation, the dataset contains the following variables: ret_excess is the net excess return for each month. mkt_excess, smb and hml are the market excess returns, the returns of the small-minus-big portfolio and the high-minus-low book-to-market ratio portfolio returns from Kenneth French’s homepage. beta is the estimated CAPM beta of the stock, measured at the beginning of month t, size is a measure of market capitalization of the stock at the beginning of month t and bm is the book-to-market ratio of the stock, measured at the beginning of month t. The columns beta, size and bm are standardized such that the monthly cross-sectional average is zero and the monthly cross-sectional standard deviation is one.


## Problem 1
We will now try to estimate the Fama French 3-factor model:
\begin{equation*}
    r_{i,t} = \alpha_i + \beta_i^\text{M} r_{m,t} + \beta_i^{\text{SMB}} r_{smb,t} + \beta_i^\text{HML} r_{hml,t} + \epsilon_{i,t}
\end{equation*}
This will be done by making a linear regression of the excess return for each stock on each of the parameters Fama French parameters. This results in the following table:

```{r, echo=FALSE}

parameter_estimates <- US_Stocks %>%
  group_by(permno) %>%
  summarise(alpha_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            alpha_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,2],
            beta_m_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[2,1],
            beta_m_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            beta_smb_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[3,1],
            beta_smb_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            beta_hml_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[4,1],
            beta_hml_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1]) 

parameter_estimates %>%
  knitr::kable(booktabs = T, digits = 4, col.names = c("Permno", "Estimate", "sd", "Estimate", "sd", "Estimate", "sd", "Estimate", "sd"), caption = "Fama French 3-factor estimates for the 8 stocks (estimated from 2000 to 2015)", align = "c") %>%
  add_header_above(c(" " = 1, "$\\hat{\\alpha}_i$" = 2, "$\\hat{\\beta}_i^{M}$" = 2, "$\\hat{\\beta}_i^{SMB}$" = 2, "$\\hat{\\beta}_i^{HML}$" = 2)) %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")


```
Table **MISSING* provides the empirical estimates for the Fama French 3-factor model for the 8 selected US stocks. The three $\beta$-estimates show the correlation between the return for stock $i$ and market return along with the two Fama French portfolio returns (SMB and HML). Here we for example see that the stock with permno 10200 has a very large negative correlation with the HML portfolio wheres the stock with permno 10252 has a fairly large positive correlation with the portfolio. For the SMB portfolio, we notice that all the stock have a positive correlation with this which indicates that the selected stocks probably have a small market cap. Permno 10200 (which is Repligen Corporation) has $\beta_i^{SMB}=1.9845$. This makes sense since the company had an average market cap of \$230 million USD in the estimated period. From the $\beta_i^{M}$-estimates we can also see that all the stocks have a positive correlation with the market. Lastly we also see that the $\alpha_i$-estimates are all very low compared to the $\beta$-estimates which indicates that most of the excess return information for the stocks can be explained by the Fama French 3-factor model. By looking at all the standard deviations for the estimates, we see that they are all very low compared to the estimators, indicating that the confidence intervals for the estimates are very low.

We will now derive the model-implied expected gross excess return $\hat{\boldsymbol{\mu}}^{FF}$ and the model-implied variance-covariance matrix $\hat{\boldsymbol{\Sigma}}^{FF}$. A bold symbol signifies that it is a vector or a matrix. We start by deriving $\hat{\boldsymbol{\mu}}^{FF}$, which is a vector consisting of the model-implied expected gross excess return for the each of the 8 stocks, where we use that $E\left[\epsilon_{i,t}\right]=0$:
\begin{align*}
    \hat{\boldsymbol{\mu}}^{FF} &= E\left[\boldsymbol{r}_{t}\right] \\
    &= E\left[\boldsymbol{\alpha} + \boldsymbol{\beta}^\text{M} \boldsymbol{r}_{m,t} + \boldsymbol{\beta}^{\text{SMB}} \boldsymbol{r}_{smb,t} + \boldsymbol{\beta}^\text{HML} \boldsymbol{r}_{hml,t} + \boldsymbol{\epsilon}_{t}\right] \\
    &= E\left[\boldsymbol{\alpha} + \boldsymbol{\beta}^\text{M} \boldsymbol{r}_{m,t} + \boldsymbol{\beta}^{\text{SMB}} \boldsymbol{r}_{smb,t} + \boldsymbol{\beta}^\text{HML} \boldsymbol{r}_{hml,t}\right] + E\left[\boldsymbol{\epsilon}_{t}\right] \\
    &= E\left[\boldsymbol{\alpha} + \boldsymbol{\beta}^\text{M} \boldsymbol{r}_{m,t} + \boldsymbol{\beta}^{\text{SMB}} \boldsymbol{r}_{smb,t} + \boldsymbol{\beta}^\text{HML} \boldsymbol{r}_{hml,t}\right] \\
    &= \frac{1}{N}\sum_{t=1}^N\left(\boldsymbol{\alpha} + \boldsymbol{\beta}^\text{M} \boldsymbol{r}_{m,t} + \boldsymbol{\beta}^{\text{SMB}} \boldsymbol{r}_{smb,t} + \boldsymbol{\beta}^\text{HML} \boldsymbol{r}_{hml,t}\right) \\
\end{align*}
In order to derive $\hat{\boldsymbol{\Sigma}}^{FF}$ then we do that in two steps. We start by deriving $V\left(r_i\right)$ and afterwards we find $Cov\left(r_i,r_j\right)$. Then we use these to create $\hat{\boldsymbol{\Sigma}}^{FF}$ since the diagonal is the matrix in the variance and the rest is the covariances between the stocks. We use that $Cov(r_{k,t}, \epsilon_{i,t}) = 0$ for all factors $k$.
\begin{align*}
    V\left(r_i\right) &= E\left[\left(r_{i,t} - E\left[r_{i,t}\right]\right)^2\right] \\
    &= E\left[r_{i,t}^2 + \left(\hat{\mu}_i^{FF}\right)^2 - 2\hat{\mu}_i^{FF} r_{i,t}\right] \\
    &= E\left[r_{i,t}^2\right] + \left(\hat{\mu}_i^{FF}\right)^2 - 2\hat{\mu}_i^{FF}E\left[r_{i,t}\right] \\
    &= E\left[r_{i,t}^2\right] + \left(\hat{\mu}_i^{FF}\right)^2 - 2\left(\hat{\mu}_i^{FF}\right)^2 \\
    &= \frac{1}{N}\sum_{t=1}^N\left(r_{i,t}^2\right) - \left(\hat{\mu}_i^{FF}\right)^2
\end{align*}
\begin{align*}
    Cov\left(r_i,r_j\right) &= E\left[r_i r_j\right] - E\left[r_i\right]E\left[r_j\right] \\
    &= \frac{1}{N}\sum_{t=1}^N\left(r_i r_j\right) - \hat{\mu}_i^{FF}\hat{\mu}_j^{FF}
\end{align*}

**INCLUDE: What determines the correlation of the returns?**
Since the returns are estimated from the Fama French 3-factor model, then it is clear to see, that what determines the correlation of the returns are a mixture of the $\beta$-estimates and the Fama French market and portfolio returns. If two stocks for example have a large positive $\beta^M$-value, and the $r_{m,t}$ is large enough to play a significant role, then both of these stocks will have a return moving in the same direction.



```{r}
# Compute the model-implied returns
compute_fama_french_returns <- function(parameter_estimates, stock_data){
  parameter_estimates <- parameter_estimates %>% select("alpha_estimate", "beta_m_estimate", "beta_smb_estimate", "beta_hml_estimate")
  stock_data <- stock_data %>% select("permno", "month", "mkt_excess", "smb", "hml")
  
  months <- unique(stock_data$month)
  N <- length(months)
  returns <- matrix(NA, ncol = length(unique(stock_data$permno)), nrow = N)
  colnames(returns) <- unique(stock_data$permno)
  
  for(i in (1:N)){
    stocks_monthly <- stock_data %>% filter(month == months[i])
    returns[i,] <- parameter_estimates$alpha_estimate + parameter_estimates$beta_m_estimate * as.numeric(stocks_monthly$mkt_excess) + parameter_estimates$beta_smb_estimate * as.numeric(stocks_monthly$smb) + parameter_estimates$beta_hml_estimate * as.numeric(stocks_monthly$hml)
  }
  returns
}

# Compute the model-implied expected gross excess return (mu_hat)
compute_fama_french_mu <- function(parameter_estimates, stock_data){
  returns <- compute_fama_french_returns(parameter_estimates, stock_data)
  colMeans(returns)
}




# Compute the model-implied variance covariance matrix (Sigma_hat)
compute_fama_french_sigma <- function(parameter_estimates, stock_data){
  
  mu <- compute_fama_french_mu(parameter_estimates, stock_data)

  stock_data <- stock_data %>% 
    ungroup() %>%
    select("permno", "month", "ret_excess", "mkt_excess", "smb", "hml") %>%
    left_join(parameter_estimates, by = "permno") %>%
    mutate(FF_return = ret_excess - (alpha_estimate + beta_m_estimate * mkt_excess + beta_smb_estimate * smb + beta_hml_estimate * hml)) 
  
  N <- length(unique(stock_data$month))
  
  stocks <- unique(parameter_estimates$permno)
  
  Sigma <- matrix(NA, ncol = length(stocks), nrow = length(stocks))
  colnames(Sigma) <- stocks
  rownames(Sigma) <- stocks
  
  for(i in 1:length(stocks)){
    stock_i <- stock_data %>% filter(permno == stocks[i])
    j <- i
    while(j <= length(stocks)){
      stock_j <- stock_data %>% filter(permno == stocks[j])
      Sigma[i,j] <- Sigma[j,i] <- as.numeric(sum(stock_i$FF_return * stock_j$FF_return)/N - mu[i]*mu[j])
      j <- j + 1
    }
  }
  Sigma
}

# Function that computes the optimal weights
compute_mean_variance_portfolio_weights <- function(mu, Sigma, gamma = 4){
  N <- ncol(Sigma)
  iota <- rep(1, N)

  # Invert Sigma 
  Sigma_inv <- solve(Sigma) 
  
  # Calculates the optimal portfolio weights
  w_mvp <- Sigma_inv %*% iota
  w_mvp <- w_mvp / sum(w_mvp)
  w_opt <- w_mvp  + 1/gamma * (Sigma_inv - w_mvp %*% t(iota) %*% Sigma_inv) %*% mu
  return(w_opt)
}


```


We now use these parameter estimates to report the computed implied mean-variance efficient portfolio weight for an investor with risk aversion $\gamma = 4$, defined by the solution to the problem:
$$\boldsymbol{\omega}^* = \arg\max_{\sum_{i=1}^N \omega_i=1} \boldsymbol{\omega}^{\prime}\hat{\boldsymbol{\mu}}^{FF} - \frac{\gamma}{2}\boldsymbol{\omega}^{\prime}\hat{\boldsymbol{\Sigma}}^{FF}\boldsymbol{\omega}$$
From standard Markowitz portfolio optimization theory, we know that the solution to this maximization problem is:
$$\boldsymbol{\omega}^{*} = \frac{1}{\gamma}\left(\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1} - \frac{1}{\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}}\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}\right)\hat{\boldsymbol{\mu}}^{FF} + \frac{1}{\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}$$
By using this, we get that the implied mean-variance portfolio weights using the Fama French 3-factor model is:

```{r, echo=FALSE}
mu <- compute_fama_french_mu(parameter_estimates, US_Stocks)
Sigma <- compute_fama_french_sigma(parameter_estimates, US_Stocks)

portfolio_weights <- t(compute_mean_variance_portfolio_weights(mu, Sigma))
rownames(portfolio_weights) <- "Portfolio weights"
portfolio_weights %>%
  knitr::kable(booktabs = T, digits = 4, caption = "Mean-variance efficient portfolio weights from using the Fama French 3-factor model-implied $\\hat{\\boldsymbol{\\mu}}^{FF}$ and $\\hat{\\boldsymbol{\\Sigma}}^{FF}$") %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")
```


## Problem 2

The parameter vector $\theta$ is a vector coefficient that we estimate. Here we don’t estimate one weight for each stock, for the different points in time, we would rather estimate weights as a single function for the chosen characteristics that will apply to all stocks over time, and this is called a portfolio policy.

We have the function for the investor problem, and it is chosing the portfolio weights $\omega_{i,t}$ and then to maximize the conditional expected utility of the portfolio's return:
$$\max\limits_{N_t} E_t[u(r_{p,t+1})] = E_t\bigg[u\bigg(\displaystyle\sum_{i=1}^{N_t}\omega_{i,t} r_{i,t+1} \bigg)\bigg]$$
We then have the parameteraization of the optimal portfolio weights as a function the characteristics for the stock's, with the simple linear specifications for the weights:

$$\omega_{i,t}=f(x_{i,t};\theta)=\bar\omega_{i,t}+\frac{1}{N_t}\theta^{\intercal}\hat x_{i,t} $$
We can the then rewrite the function for the conditional expected utility, with an unconditional optimization with respect to the coefficients $\theta$:
$$\max\limits_{\theta} E_t[u(r_{p,t+1})] = E_t\bigg[u\bigg(\displaystyle\sum_{i=1}^{N_t}f(x_{i,t};\theta) r_{i,t+1} \bigg)\bigg]$$

We can then estimate $\theta$ by maximizing the corresponding sample analog

$$\max\limits_{\theta} \frac{1}{T}\displaystyle\sum_{i=0}^{T-1}u(r_{p,t+1}) =\frac{1}{N}\displaystyle\sum_{i=0}^{T-1} u \bigg(\displaystyle\sum_{i=1}^{N_t}f(x_{i,t};\theta) r_{i,t+1} \bigg)$$

To estimate $\theta$ we maximize the linear policy case  fucntion:
$$\max\limits_{\theta} \frac{1}{N}\displaystyle\sum_{i=0}^{T-1} \bigg(\displaystyle\sum_{i=1}^{N_t}\bigg (\bar\omega_{i,t}+\frac{1}{N_t}\theta^{\intercal}\hat x_{i,t} \bigg) r_{i,t+1} \bigg)$$

The most important aspect of the coefficient $\theta$ is that the parameterization is constant across assets through time. If we have a constant coefficient across assets, then the weight in the portfolio for each stock will depend on the characteristics of the stock and not on the history of the return on the stock. 
And based on this, if we have two stocks that are close to each other in characteristics, which are related to the expected return and risk, with different sample returns, should even then have the same weight in the portfolio.

It is reltivly easy to optimizing a portfolio composed of a large number of stocks. But the burden of this type of optimization does not come from the number of assets, but more from the number of characteristics. Also only optimize the entire portfolio based on the parameters we choose, which will parsimony also reduce the risk of in-sample and overfitting. This is because the coefficients will only deviate from zero if there is a combination of risk and return across assets consistently. This will also affect the optimization in the aspect that it tends not to take extreme values.   

If we look at the function for the simple linear specification for the portfolio weights, it will conveniently nests all the long-short portfolios, which is constructed from the Fama and French model. 









```{r}

US_Stocks <- US_Stocks %>% group_by(permno)

compute_portfolio_weights <- function(theta,
                                      data) {
  data %>%
    # group_by(month) %>%
    mutate(
      characteristic_tilt = beta*theta[1]+size*theta[2]+bm*theta[3]
    )%>%
    mutate(
      # Definition of benchmark weight
      weight_benchmark = 1/N,
       # Parametric portfolio weights
      weight_tilt = weight_benchmark + characteristic_tilt, 
      # Weights sum up to 1
      weight_tilt = weight_tilt / sum(weight_tilt) 
    ) %>%
    ungroup()
}



view(compute_portfolio_weights(theta,US_Stocks))








```

## Problem 3

```{r}
Sub_US_Stocks <- US_Stocks %>% filter(month<="2015-12-31")

Sub_US_Stocks %>% group_by(month) %>% view()

T <- length(unique(Sub_US_Stocks$month))

rt <- Sub_US_Stocks %>% select(permno, ret_excess) %>% group_by(permno) %>% summarise(across(ret_excess,sum))

mutilde <- 1/T*rt

rmu <- Sub_US_Stocks %>% select(permno, ret_excess) %>% group_by(permno) %>% summarise(across(ret_excess,sum)) %>% mutate()

sigmatilde <- 1/(T-1)*


```



