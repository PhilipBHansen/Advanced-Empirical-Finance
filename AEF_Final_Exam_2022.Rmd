---
title: "AEF Exam 2022"
author: "Exam numbers: 48, 49 and 57"
date: "Date: 13/06/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  echo = FALSE,
  fig.align = "center",
  warning = FALSE,
  message = FALSE,
  out.width = ".65\\linewidth"
)

########################
### BEGIN USER INPUT ###
######################## 

# Automatic setup for working directory for authors of this file
tmp <- getwd()
if(substr(tmp,1,12) == "C:/Users/Mie"){
  # Mie
  setwd("C:/Users/Mie/OneDrive/CBS/Kandidat/data")
} else if(substr(tmp,1,14) == "C:/Users/Alexm"){
  # Alexander
  setwd("C:/Users/Alexm/Documents")
} else{
  # Philip
  setwd("C:/Users/phili/OneDrive - CBS - Copenhagen Business School/Desktop/Code/R - code/AEF")
}

# If NON-AUTHOR runs this code, please insert your own path to the working directory where you store tidy_finance.sqlite and uncomment the line below:
# setwd("INSERT PATH TO YOUR TIDY_FINANCE FILE")


# The following input is used in part 2 of the exam in problem 1 and 2
gamma_default <- 4

######################
### END USER INPUT ###
######################


# Loading packages
library(tidyquant)
library(tidyverse)
library(RSQLite)
library(lubridate)
library(sandwich)
library(lmtest)
library(scales)
library(kableExtra)


# Changes decimals from having e to having 0s
options(scipen = 999)

# Loading relevant data for part 1 of the exam
tidy_finance <- dbConnect(SQLite(), "tidy_finance.sqlite", extended_types = TRUE) # Connect to sql
crsp_monthly <- tbl(tidy_finance, "crsp_monthly") %>% collect() %>% select("permno", "month", "ret_excess", "mktcap", "mktcap_lag")
ff_monthly <- tbl(tidy_finance, "factors_ff_monthly") %>% collect() %>% select("month", "mkt_excess")

# Loading relevant data for part 2 of the exam
US_Stocks <- read.csv(file = "data_exam2022.csv")
#Generate a subset of the data with dates 2015-12-31 or earlier
Sub_US_Stocks <- US_Stocks %>% filter(month < "2016-01-01")
#Out of sample periode
Out_Of_Sample <- US_Stocks %>% filter(month >= "2016-01-01")

```

## Contribution from each student
The whole report is made in collaboration with each other where we have all helped with each problem. The main author of each section can be seen as follows:  
**48**: Part 1: exercise **MISSING** and Part 2: problem 2 (text) and problem 3  
**49**: Part 1: exercise **MISSING** and Part 2: problem 2 (coding)  
**57**: Part 1: exercise **MISSING** and Part 2: problem 1  

\newpage
\pagenumbering{arabic}

# Exam part 1



## Exercise 1
The financial stock data for this assignment comes from the CRSP-universe and includes stock data from "1989-02-01" to "2020-12-01". We load the variables *permno*, *month*, *ret_excess*, *mktcap* and *mktcap_lag*. Furthermore, we also use the monthly Fama-French data which includes the variables *month* and *mkt_excess*. Below is the definition of the variables used in the assignment:  
1. *Permno*: Permno is a security identification number.   
2. *ret_excess*: This is the excess return, which is the return on the stock minus the return we get on the risk-free asset over the same period. So the excess return shows the extra return you get by investing in a risky asset compared to just putting your money in the bank (investing in the risk-free asset).  
3. *mktcap*: Market capitalization (or market cap) is the total value of the company. It is calculated as the total amount of outstanding shares of a company multiplied with the stock price. This makes it easier to compare the size of each company to one another and to the market in general.  
4. *mkt_excess*: This is the excess return for the whole market combined.  

In order to get a sense of the data, we create the following summary statistics, where we calculate the mean, standard deviation and quartiles for both the excess return and the market capitalization for each month and then we average these results over all months. This gives us the following table:

```{r summary statistics, echo=FALSE}

# Generates an empty data frame, assigns columns for summary statistics and loads a vector with the variables we wish to summarize
summary1 <- data.frame(matrix(ncol=7, nrow=2)) #There are 7 summary statistics and 2 variables
colnames(summary1) <- c("mean", "sd", "min", "Q1","median", "Q3", "max")
var_names <- c("ret_excess",  "mktcap")

# Loops through all the chosen variables and calculates mean, sd, min, Q1, median, Q3 and max for each month then takes the average of those results.  
for(i in 1:2){
  summary1[i,] <- crsp_monthly %>%
    group_by(month) %>%
    summarise(across(var_names[i], list(mean = mean, 
                                        sd = sd, 
                                        min = min,
                                        q25 = ~quantile(., 0.25),
                                        median = median,
                                        q75 = ~quantile(., 0.75), 
                                        max = max),
                                        .names = "{.fn}  ")
                                        ) %>%
    summarise(across(-month, mean))
}

# Assigns relevant row names
rownames(summary1) <- c("Excess return", "Market cap")

# Prints the summary nicely in a table
summary1 %>% 
  knitr::kable(booktabs = T, digits = 4, caption = "Summary statistics of the excess return and the market cap") %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")

```

Table 1 shows that the cross-sectional mean of the excess return and market capitalization is 0.83\% and 1815 million USD, respectively. On average the monthly excess return varies from -69.06\% to 267.75\% where the market capitalization on average varies from 0.7 to 242,415 million USD. Furthermore, it is seen that the mean is larger than the median for both variables. This indicates that the distribution of the data is positively skewed (right-skewed). 


## Exercise 2

The reason why *crsp_monthly %>% group_by(permno) %>% mutate(ret_excess_lag = lag(ret_excess))* does not provide the correct result if there are non-explicit missing values in the time series is, that the lag function doesn't differentiate between one-month lag and just the closest lag available. If data for a specific month, lets say May, doesn't exist, then it just takes April as the lagged value instead, which would be wrong. Therefore, a better way to find the lagged excess return would be to copy the data to a new data frame (only including permno, month and excess return) where you overwrite the month to be the next month. This means that all the data in the new data frame is now depicted as being one month behind of what it actually is. Then you re-name the excess return column to instead depict lagged excess return and lastly you drop all the NAs in the data frame. By now innerjoining this data frame to the original on month and permno you now get the lagged excess return variable as well.


```{r summerise for autocorrelation, echo=FALSE}
# The following implementation for creating the lag is inspired by peer grade
# Creating a new table where the month in crsp_monthly is moved 1 month ahead and then the excess return is renamed to ret_excess_lag and na dropped
crsp_monthly_month_changed <- crsp_monthly %>% 
  mutate(month = month %m+% months(1)) %>% 
  select(permno, month, ret_excess_lag = ret_excess) %>% 
  drop_na()

# Using inner join on month and permno to add ret_excess_lag and only keep complete data where there is no na
crsp_monthly_new <- crsp_monthly %>% 
  inner_join(crsp_monthly_month_changed, by = c("permno", "month"))

# Calculation the correlation between the excess return and the lagged excess return
return_correlation <- cor(crsp_monthly_new$ret_excess, crsp_monthly_new$ret_excess_lag)

```
In order to investigate whether or not the returns exhibit autocorrelation of lag 1, then we can find the correlation between the excess return and the lagged excess return, which is: `r round(return_correlation, 4)`. This negative correlation implies that the returns move in opposite direction from the lagged returns. Therefore, if the returns have been positive last month, then they are likely to be negative this month and vice versa. 


## Exercise 3
We start by adding a new column showing the momentum of a company. The momentum is calculated as the growth of the market capitalization for a company over the past year. The market cap with 12 months lag is calculated in the same way as described in exercise 2 with the lagged excess return:
$$
Mom_{i,t} = 100\cdot\frac{(mc_{i,t-1}-mc_{i,t-12})}{mc_{i,t-12}}
$$
Computing momentum as the relative change in prices or as the relative change in market capitalization is fundamentally identical. However when working with data over long time periods, market capitalization has a profound edge over prices. When using prices, the momentum will be affected by noise caused by operations in the financial market which has nothing to with the company's market valuation. The issuing of new stocks will naturally dilute the value of a single stock causing prices to drop, but it will not affect the market capitalization. Suppose a company decides to do a stock split. This will cut the price of the stock in half, but leave the market capitalization unchanged which promotes the use of market capitalization over prices.

```{r lag for 12 months, echo=FALSE}

# Creating a new table where the month in crsp_monthly is moved 12 months ahead and then the mkt_cap is renamed to mktcap_lag_12 and na dropped
crsp_monthly_month_changed_12 <- crsp_monthly %>% 
  mutate(month = month %m+% months(12)) %>% 
  select(permno, month, mktcap_lag_12 = mktcap) %>% 
  drop_na()

# Using inner join on month and permno to add ret_excess_lag and only keep complete data where there is no na
crsp_monthly_mom <- crsp_monthly %>% 
  inner_join(crsp_monthly_month_changed_12, by = c("permno", "month"))

# calculation of mom and add to a new column
crsp_monthly_mom <- crsp_monthly_mom %>% 
  group_by(permno) %>% 
  mutate(mom = 100*(mktcap_lag - mktcap_lag_12) / mktcap_lag_12) 

# Generates an empty data frame and assigns columns for summary statistics
summary2 <- data.frame(matrix(ncol=9, nrow=1)) #There are 9 summary statistics and 1 variable
colnames(summary2) <- c("mean", "sd", "min", "5th", "25th","median", "75th", "95th", "max")

# Calculates mean, sd, min, 5th percentile, 25th percentile, median, 75th percentile, 95th percentile and max for each month and then takes the average of those results.
summary2[1,] <- crsp_monthly_mom %>%
  group_by(month) %>%
  summarise(across(mom, list(mean = mean, 
                             sd = sd, 
                             min = min,
                             q05 = ~quantile(., 0.05),
                             q25 = ~quantile(., 0.25),
                             median = median,
                             q75 = ~quantile(., 0.75),
                             q95 = ~quantile(., 0.95),
                             max = max),
                   .names = "{.fn}  ")) %>%
  summarise(across(-month, mean))

# Assigns relevant row names
rownames(summary2) <- "Momentum"

# Prints the summary nicely in a table
summary2 %>% 
  knitr::kable(booktabs = T, digits = 2, caption = "Summary statistics of the momentum") %>% 
  kable_paper("hover", full_width = T) %>% 
  kable_styling(latex_options = "HOLD_position")

# Calculates the correlation between momentum and the logarithm of the market cap
mom_mktcap_correlation <- cor(crsp_monthly_mom$mom, log(crsp_monthly_mom$mktcap))

```
Table 2 shows that the cross-sectional mean of the momentum is 19 while the median is only 5.6. As in table 1, this indicates a positive skew (right-skew). There are therefore very large momentum values which have a big impact on the mean, which is also seen by the average maximum momentum being 3200. We can also notice that the standard deviation is 96 and therefore quite high (especially when comparing to a mean of 19). Another indication of the extreme momentum-values' effect is the difference between the 95th percentile and the maximum. Since the 95th percentile is "only" 118, this means that only 5% of the observations have a momentum of 118 or larger.

By calculating the correlation between *momentum* and $log(mc_{i,t})$ we get a value of `r round(mom_mktcap_correlation, 4)`. We therefore see a positive correlation between momentum and $log(mc_{i,t})$. If we can observe positive momentum over the past year, then we can to some degree expect a larger market cap next month.


## Exercise 4
Now we want to examine the relationship between momentum and future stock returns. First, we start by dividing the stocks into 10 portfolios based on the momentum size for a given stock in each period. In the following, we have calculated the equal-weighted average values of the momentum and market capitalization for each of the 10 portfolios:

```{r Relation, echo=FALSE}
# Arranges data by month instead of permno
crsp_monthly_mom <- crsp_monthly_mom %>% 
  arrange(month)

# Calculating the decile breakpoints for the mom for each months and defines which portfolio belongs to each month
mom_portfolios <- crsp_monthly_mom %>%
  group_by(month) %>%
  mutate(breakpoint_1 = quantile(mom, probs = .1),
         breakpoint_2 = quantile(mom, probs = .2),
         breakpoint_3 = quantile(mom, probs = .3),
         breakpoint_5 = quantile(mom, probs = .5),
         breakpoint_4 = quantile(mom, probs = .4),
         breakpoint_6 = quantile(mom, probs = .6),
         breakpoint_7 = quantile(mom, probs = .7),
         breakpoint_8 = quantile(mom, probs = .8),
         breakpoint_9 = quantile(mom, probs = .9),
         portfolio = case_when(mom <= breakpoint_1 ~ 1,
                               mom > breakpoint_1 & mom <= breakpoint_2 ~ 2,
                               mom > breakpoint_2 & mom <= breakpoint_3 ~ 3,
                               mom > breakpoint_3 & mom <= breakpoint_4 ~ 4,
                               mom > breakpoint_4 & mom <= breakpoint_5 ~ 5,
                               mom > breakpoint_5 & mom <= breakpoint_6 ~ 6,
                               mom > breakpoint_6 & mom <= breakpoint_7 ~ 7,
                               mom > breakpoint_7 & mom <= breakpoint_8 ~ 8,
                               mom > breakpoint_8 & mom <= breakpoint_9 ~ 9,
                               mom > breakpoint_9 ~ 10)) %>%
  select("permno", "month", "ret_excess", "mktcap", "mktcap_lag", "mktcap_lag_12", "mom", "portfolio") %>%
  mutate(portfolio = as.factor(portfolio))

# Saving this data frame for later use
mom_portfolios_raw <- mom_portfolios

# Creating the table of equal weighted average of momentum and market cap
mom_portfolios %>% group_by(portfolio) %>%
  summarise('average momentum' = mean(mom),'average market capitalization' = mean(mktcap)) %>%
  knitr::kable(booktabs = T, 
               digits = c(0, 2, 0), 
               col.names = c("Portfolio number", "Average momentum", "Average market capitalization"), 
               caption = "Equal weighted momentum-sorted portfolios with average momentum and market capitalization") %>% 
  kable_paper("hover", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position")

```
In table 3 we see that the momentum is increasing with the portfolio number (which makes sense as per the definition of the portfolios). We also notice that the average market capitalization is increasing from portfolio 1-7 and then begins to fall back down for the last three portfolios with the highest momentum.

We now calculate the value-weighted monthly excess returns for each portfolio which is depicted in the table below:

```{r, echo=FALSE}
# Creating the monthly portfolio value-weighted excess returns
mom_portfolios <- mom_portfolios %>%
  group_by(month, portfolio) %>%
  summarize(ret_excess = weighted.mean(ret_excess, mktcap_lag), .groups = "drop")

# Adds the Fama-French market excess return to the data frame
mom_portfolios <- mom_portfolios %>%
  left_join(ff_monthly, by = "month")

# Finding the CAPM alpha by regressing the data onto the market excess return
mom_portfolios %>% 
  group_by(portfolio) %>%
  summarise(alpha = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[1]),
            beta = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[2]),
            ret_excess = mean(ret_excess)) %>%
  knitr::kable(booktabs = T, 
               digits = 4, 
               col.names = c("Portfolio number", "CAPM alpha", "Market beta", "Average value-weighted excess return"), 
               caption = "CAPM alpha, beta and excess return for the value-weighted momentum-sorted portfolios") %>% 
  kable_paper("hover", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position")

```

In table 4 we see that the average value-weighted returns and the CAPM alphas (risk-adjusted performance) are increasing in the portfolios (with the exception of portfolios 6 and 7). We also see that all of the portfolios are very correlated with the market return which is depicted in the Market beta. Most of the portfolios have a Market beta around 1 which indicates that they move more or less like the market. Portfolio 1 is however extremely correlated with the market returns, so whenever the market moves a little bit in one direction, then this portfolio moves a lot in the same direction, making the fluctuations very large. Since we are interested in looking at the CAPM alphas of the different portfolios, we have depicted them in the graph below, so they are easier to compare to each other.

```{r fig1, out.width = '80%', echo=FALSE}
# Calculating the CAPM (linear regression of the excess return on the market excess return)
mom_portfolios_summary <- mom_portfolios %>%
  group_by(portfolio) %>%
  summarise(alpha = summary(lm(ret_excess ~ mkt_excess))$coefficients[1])

# Plot for CAPM alpha
mom_portfolios_summary %>% 
  ggplot(aes(x = as.factor(portfolio), y = alpha, fill = as.factor(portfolio))) +
  geom_bar(stat = "identity") +
  labs(title = "CAPM alphas of the momentum-sorted portfolios with value-weighted returns",
       x = "Momentum-sorted portfolios",
       y = "CAPM alpha",
       fill = "Portfolio") +
  scale_y_continuous(labels = percent) +
  theme(legend.position = "None") + 
  theme_bw()

```

As seen in the graph above, it looks like there is a large negative CAPM alpha for portfolio 1 and  a fairly large positive CAPM alpha for portfolio 10. We therefore try to analyse the momentum strategy where we go long in portfolio 10 (which has the highest momentum) and short in portfolio 1 (which has the lowest momentum). So for each month we compute the return of this long-short portfolio by taking the value-weighted return for portfolio 10 and subtracting the value-weighted return for portfolio 1. Running a linear regression of the long-short return on the market return gives us the following table. The last row in the table is computed as a t-test to investigate if the true mean of the return could be 0.


```{r, echo=FALSE}
# Creating the returns for the long-short portfolio
long_short_portfolio <- mom_portfolios %>%
  filter(portfolio %in% c(1, 10)) %>%
  mutate(portfolio = case_when(portfolio == 10 ~ "high",
                               portfolio == 1 ~ "low")) %>%
  pivot_wider(month, names_from = portfolio, values_from = ret_excess) %>%
  mutate(long_short = high - low) %>%
  left_join(ff_monthly, by = "month")

# Calculating the portfolio turnover (using the mom_portfolios_raw dataset before grouping stocks together in portfolios)
months <- unique(mom_portfolios_raw$month) # number of months in the dataset

# Creating initial portfolio weights 
w_prev <- mom_portfolios_raw %>% 
  filter(month == months[1]) %>% 
  ungroup() %>% 
  filter(portfolio %in% c(1, 10)) %>% 
  mutate(weight = mktcap_lag / sum(mktcap_lag)) %>%
  select(permno, weight)

# Initializing total turnover sum
turnover_mom <- 0

#####################################
### WARNING: TAKES A WHILE TO RUN ###
#####################################

# Looping through all months in order to calculate changes in portfolio weights
for(i in (2:length(months))){
  w_new <- mom_portfolios_raw %>% 
    filter(month == months[i]) %>% 
    ungroup() %>% 
    filter(portfolio %in% c(1, 10)) %>% 
    mutate(weight = mktcap_lag / sum(mktcap_lag)) %>%
    select(permno, weight)
  
  # Joining the new and previous portfolio weights together by permno in order to find difference (setting NA to 0)
  tmp <- w_prev %>% full_join(w_new, by="permno")
  tmp[["weight.x"]][is.na(tmp[["weight.x"]])] <- 0
  tmp[["weight.y"]][is.na(tmp[["weight.y"]])] <- 0
  
  # Updating turnover sum
  turnover_mom <- turnover_mom + sum(abs(tmp$weight.x - tmp$weight.y))
  
  # Updating previous portfolio weights
  w_prev <- w_new
}

# Calculating average monthly turnover
turnover_mom <- turnover_mom / length(months)

# Making a linear regression of the portfolio return om the market return in order to get the CAPM values (and then renaming the rows)
long_short_summary <- summary(lm(long_short ~ mkt_excess, data=long_short_portfolio))$coefficients
tmp <- t.test(long_short_portfolio$long_short) # Creating a t.test for the return estimate
long_short_summary <- rbind(long_short_summary, c(tmp$estimate, tmp$stderr, tmp$statistic, tmp$p.value))
row.names(long_short_summary) <- c("CAPM alpha", "Market beta", "Portfolio return")

# Using the linear regression values to depict as a table
long_short_summary %>% 
  knitr::kable(booktabs = T, 
               digits = 4, 
               caption = "CAPM alpha, beta and excess return for the long-short portfolio based on value-weighted momentum-sorted portfolios") %>%
  kable_paper("hover", full_width = T) %>% 
  kable_styling(latex_options = "HOLD_position")

```

If we start by looking at the bottom row which depicts the results for the return, we see that the portfolio does in fact deliver an average return above 0 (an estimate of 0.75%). We see this by conducting a t-test where the null hypothesis is that the true mean is 0. By looking at the p-value we can reject this on a 5% significance level. From the CAPM regression we also see that we get a positive alpha, where we likewise can reject a null hypothesis of the true alpha being 0. By comparing the long-short portfolio alpha with the alphas for portfolio 1 and 10 from table 5 we see that the alpha has now increased. Instead of just going long in portfolio 10, we now get a higher alpha by investing in the long-short portfolio.


## Exercise 5
In the following, we will calculate the CAPM alphas using the k-month-ahead excess returns for $k\in\{1,3,6,12\}$. Since we lose a few observations by having to find the k-months ahead returns, then in order to most efficiently compare all the results, we have chosen to only calculate the CAPM values for observations where we have found all the specific k-months ahead returns. The k-months ahead portfolio returns are calculated as value-weighted returns based on the lagged market cap value (since this is known at the time the portfolio is constructed). It is assumed that the 1-month ahead is just the standard excess return and therefore that 3-months ahead should be calculated as the excess return two months later. The reason for this assumption is that the lagged variables are meant to be known at the time we construct the portfolio, where the excess return is then the result of this. Hence, it must be the 1-month ahead return.

```{r  Repeat the univariate portfolio, echo=FALSE}
# Creating the 3, 6, and 12 months ahead returns by moving back the respective month by 2, 5 or 11 months (since ret_excess is already 1-month ahead) and then adding the fama-french k-month-ahead market return for comparison (again the creation of lag is inspired by peer grade)
excess_return_3_ahead <- crsp_monthly_mom %>% 
  left_join(ff_monthly, by = "month") %>%
  mutate(month = month %m+% months(-2)) %>% 
  select(permno, month, ret_excess_3 = ret_excess, mkt_excess_3 = mkt_excess) %>% 
  drop_na()

excess_return_6_ahead <- crsp_monthly_mom %>% 
  left_join(ff_monthly, by = "month") %>%
  mutate(month = month %m+% months(-5)) %>%
  select(permno, month, ret_excess_6 = ret_excess, mkt_excess_6 = mkt_excess) %>% 
  drop_na()

excess_return_12_ahead <- crsp_monthly_mom %>%
  left_join(ff_monthly, by = "month") %>%
  mutate(month = month %m+% months(-11)) %>% 
  select(permno, month, ret_excess_12 = ret_excess, mkt_excess_12 = mkt_excess) %>% 
  drop_na()

# Combining all the k-months-ahead returns in one data frame
crsp_monthly_k_months <- crsp_monthly_mom %>%
  inner_join(excess_return_3_ahead, by = c("permno", "month")) %>%
  inner_join(excess_return_6_ahead, by = c("permno", "month")) %>%
  inner_join(excess_return_12_ahead, by = c("permno", "month"))

# Arranges data by month instead of permno
crsp_monthly_k_months <- crsp_monthly_k_months %>% 
  arrange(month)

# Calculating the decile breakpoints for the mom for each months and defines which portfolio belongs to each month
mom_portfolios_k_ahead <- crsp_monthly_k_months %>%
  group_by(month) %>%
  mutate(breakpoint_1 = quantile(mom, probs = .1),
         breakpoint_2 = quantile(mom, probs = .2),
         breakpoint_3 = quantile(mom, probs = .3),
         breakpoint_4 = quantile(mom, probs = .4),
         breakpoint_5 = quantile(mom, probs = .5),
         breakpoint_6 = quantile(mom, probs = .6),
         breakpoint_7 = quantile(mom, probs = .7),
         breakpoint_8 = quantile(mom, probs = .8),
         breakpoint_9 = quantile(mom, probs = .9),
         portfolio = case_when(mom <= breakpoint_1 ~ 1,
                               mom > breakpoint_1 & mom <= breakpoint_2 ~ 2,
                               mom > breakpoint_2 & mom <= breakpoint_3 ~ 3,
                               mom > breakpoint_3 & mom <= breakpoint_4 ~ 4,
                               mom > breakpoint_4 & mom <= breakpoint_5 ~ 5,
                               mom > breakpoint_5 & mom <= breakpoint_6 ~ 6,
                               mom > breakpoint_6 & mom <= breakpoint_7 ~ 7,
                               mom > breakpoint_7 & mom <= breakpoint_8 ~ 8,
                               mom > breakpoint_8 & mom <= breakpoint_9 ~ 9,
                               mom > breakpoint_9 ~ 10)) %>%
  select("permno", "month", "ret_excess", "ret_excess_3", "ret_excess_6", "ret_excess_12", "mktcap", "mktcap_lag", "mktcap_lag_12", "mom", "portfolio") %>%
  mutate(portfolio = as.factor(portfolio))

# Creating monthly portfolio value-weighted excess returns
mom_portfolios_k_ahead <- mom_portfolios_k_ahead %>%
  group_by(month, portfolio) %>%
  summarise(ret_excess = weighted.mean(ret_excess, mktcap_lag),
            ret_excess_3 = weighted.mean(ret_excess_3, mktcap_lag),
            ret_excess_6 = weighted.mean(ret_excess_6, mktcap_lag),
            ret_excess_12 = weighted.mean(ret_excess_12, mktcap_lag),
            .groups = "drop")

# Adds the Fama-French k-months-ahead market excess return to the data frame
excess_return_3_ahead <- excess_return_3_ahead %>% ungroup() %>% select(month, mkt_excess_3) %>% unique()
excess_return_6_ahead <- excess_return_6_ahead %>% ungroup() %>% select(month, mkt_excess_6) %>% unique()
excess_return_12_ahead <- excess_return_12_ahead %>% ungroup() %>% select(month, mkt_excess_12) %>% unique()
mom_portfolios_k_ahead <- mom_portfolios_k_ahead %>%
  left_join(ff_monthly, by = "month") %>%
  left_join(excess_return_3_ahead, by = "month") %>%
  left_join(excess_return_6_ahead, by = "month") %>%
  left_join(excess_return_12_ahead, by = "month")

# Finding the CAPM alpha by regressing the data onto the market excess return
k_months_ahead_alphas <- mom_portfolios_k_ahead %>%
  group_by(portfolio) %>%
  summarise(alpha_1 = as.numeric(lm(ret_excess ~ mkt_excess)$coefficients[1]),
            alpha_3 = as.numeric(lm(ret_excess_3 ~ mkt_excess_3)$coefficients[1]),
            alpha_6 = as.numeric(lm(ret_excess_6 ~ mkt_excess_6)$coefficients[1]),
            alpha_12 = as.numeric(lm(ret_excess_12 ~ mkt_excess_12)$coefficients[1]))

# Printing a table of the alphas
k_months_ahead_alphas %>%
  knitr::kable(booktabs = T, 
               digits = 4, 
               col.names = c("Portfolio", "Alpha 1 month ahead", "Alpha 3 months ahead", "Alpha 6 months ahead", "Alpha 12 months ahead"), 
               caption = "CAPM alphas for the value-weighted momentum-sorted portfolios") %>%
  kable_paper("hover", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position")


```



```{r fig2, out.width = '80%', echo=FALSE}

# Creating a tall table with all k-months-ahead alphas together in order to create combined plot
k_months_ahead_alphas_tall <- k_months_ahead_alphas %>% 
  gather(key = alphas, value = Value, alpha_1:alpha_12) %>%
  # Below is used alpha1, alpha2, alpha3, alpha4 so that they have the right order in the plot
  mutate(alphas = case_when(alphas == "alpha_1" ~ "Alpha1",
                            alphas == "alpha_3" ~ "Alpha2",
                            alphas == "alpha_6" ~ "Alpha3",
                            alphas == "alpha_12" ~ "Alpha4"))

# Plot for CAPM alphas
k_months_ahead_alphas_tall %>% 
  ggplot(aes(x = as.factor(portfolio), y = Value, fill = alphas)) +
  geom_col(position = "dodge") +
  labs(title = "CAPM alphas of the momentum-sorted portfolios with the k-months-ahead returns",
       x = "Momentum-sorted portfolios",
       y = "CAPM alpha",
       fill = "Portfolio") +
  scale_fill_discrete(labels = c("1-month-ahead", "3-months-ahead", "6-months-ahead", "12-months-ahead")) +
  scale_y_continuous(labels = percent) +
  theme_bw() +
  theme(legend.position = "bottom") + 
  theme(plot.title = element_text(size = 10))

```

The graph above shows the CAPM alphas for all the k-months-ahead returns (with $k=1,3,6,12$) for all 10 momentum-sorted portfolios. Something that is very noticeable is that the CAPM alpha for the 12-months-ahead returns has opposite signs for most of the portfolios. For portfolio 1 it shows a positive CAPM alpha, where the shorter lags show a negative CAPM alpha. As we move into the middle portfolios then the CAPM alpha becomes smaller for all the k-months-ahead returns. According to this investigation, portfolio 1 with a time horizon of 12 months seems to predict the highest risk-adjusted performance. This horizon also continues to deliver positive CAPM alphas for all portfolios except portfolios 9 and 10. However, by looking at the 3-months-ahead CAPM alphas, then we see the same movements as for the original 1-month-ahead just larger. It could therefore suggest that creating the long-short portfolio as we did in exercise 4 would result in an even larger risk-adjusted performance.

## Exercise 6

```{r, echo=FALSE}

# Creating the returns for the long-short portfolio
our_mom_strategy_raw <- mom_portfolios_raw %>%
  #filter(portfolio %in% c(1, 2, 9, 10)) %>%
  group_by(permno) %>%
  mutate(lag_portfolio = lag(portfolio)) %>%
  filter(portfolio %in% c(1, 2, 9, 10)) %>%
  mutate(updated_portfolio = case_when(portfolio == 1 ~ 1,
                                       portfolio == 10 ~ 10,
                                       portfolio == 2 & lag_portfolio == 1 ~ 1,
                                       portfolio == 9 & lag_portfolio == 10 ~ 10,
                                       portfolio == 2 & lag_portfolio == 2 ~ 1,
                                       portfolio == 9 & lag_portfolio == 9 ~ 1
                                       ))

# Creating monthly portfolio value-weighted excess returns
our_mom_strategy <- our_mom_strategy_raw %>%
  group_by(month, updated_portfolio) %>%
  summarize(ret_excess = weighted.mean(ret_excess, mktcap_lag), .groups = "drop") %>% 
  drop_na()

# Adds the Fama-French market excess return to the data frame
our_mom_strategy <- our_mom_strategy %>%
  left_join(ff_monthly, by = "month")

# Creating the returns for the long-short portfolio
our_mom_long_short_portfolio <- our_mom_strategy %>%
  filter(updated_portfolio %in% c(1, 10)) %>%
  mutate(updated_portfolio = case_when(updated_portfolio == 10 ~ "high",
                                       updated_portfolio == 1 ~ "low")) %>%
  pivot_wider(month, names_from = updated_portfolio, values_from = ret_excess) %>%
  mutate(long_short = high - low) %>%
  left_join(ff_monthly, by = "month")


# Making a linear regression of the portfolio return om the market return in order to get the CAPM values (and then renaming the rows)
our_mom_long_short_summary <- summary(lm(long_short ~ mkt_excess, data=our_mom_long_short_portfolio))$coefficients
tmp <- t.test(our_mom_long_short_portfolio$long_short) # Creating a t.test for the return estimate
our_mom_long_short_summary <- rbind(our_mom_long_short_summary, c(tmp$estimate, tmp$stderr, tmp$statistic, tmp$p.value))
row.names(our_mom_long_short_summary) <- c("CAPM alpha", "Market beta", "Portfolio return")

# Using the linear regression values to depict as a table
our_mom_long_short_summary %>% 
  knitr::kable(booktabs = T, 
               digits = 4, 
               caption = "CAPM alpha, beta and excess return for the new long-short portfolio based on value-weighted momentum-sorted portfolios") %>%
  kable_paper("hover", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position")

# Calculating the portfolio turnover (using the mom_portfolios_raw dataset before grouping stocks together in portfolios)
months <- unique(mom_portfolios_raw$month) # number of months in the dataset
# Creating initial portfolio weights 
w_prev <- our_mom_strategy_raw %>% 
  filter(month == months[1]) %>% 
  ungroup() %>% 
  filter(updated_portfolio %in% c(1, 10)) %>% 
  mutate(weight = mktcap_lag / sum(mktcap_lag)) %>%
  select(permno, weight)

# Initializing total turnover sum
our_mom_turnover <- 0


#####################################
### WARNING: TAKES A WHILE TO RUN ###
#####################################

# Looping through all months in order to calculate changes in portfolio weights
for(i in (2:length(months))){
  w_new <- our_mom_strategy_raw %>% 
    filter(month == months[i]) %>% 
    ungroup() %>% 
    filter(updated_portfolio %in% c(1, 10)) %>% 
    mutate(weight = mktcap_lag / sum(mktcap_lag)) %>%
    select(permno, weight)
  # Joining the new and previous portfolio weights together by permno in order to find difference (setting NA to 0)  
  tmp <- w_prev %>% full_join(w_new, by="permno")
  tmp[["weight.x"]][is.na(tmp[["weight.x"]])] <- 0
  tmp[["weight.y"]][is.na(tmp[["weight.y"]])] <- 0
  
  # Updating turnover sum
  our_mom_turnover <- our_mom_turnover + sum(abs(tmp$weight.x - tmp$weight.y))
  
  # Updating previous portfolio weights
  w_prev <- w_new
}

# Calculating average monthly turnover
our_mom_turnover <- our_mom_turnover / length(months)


```

Most academic studies ignore real world costs, which could prove to be an issue for the momentum portfolio. We have seen that the momentum strategy has quite a high turnover and this might lead to momentum becoming too expensive to trade compared to its return premium. It is very likely that the turnover of a portfolio sorted on size instead would be significantly smaller than that of a momentum sorted portfolio. A company that is large will most likely remain so in the foreseeable future. Take Apple as an example, and imagine its stock price dropping 10%. This would imply severe negative momentum, but it would, for a decent amount of time, remain a huge company. The same goes for really small companies. Imagine your local bakery doing an IPO and doubling its market cap in a year. This is an enormous positive momentum, but it does not make it a Fortune 500 or anything close to it.

The assumption of perfectly divisible assets might also have an effect on cost in the real world. However, this problem dissapears as the value of the portfolio becomes sufficiently large. Asset liquidity might also be an issue as some assets simply cannot be traded at the pace a momentum strategy requires. At least not without trading at a discount, which most likely would leave the strategy worse off.

To capture the momentum premium while lowering the turnover, we suggest a strategy that chooses assets the same way as the standard long-short strategy. Instead of dropping the position as soon as its momentum moves out of the top or bottom 10%, we hold it until it hast moved out of the top or bottom 20%. This limits the turnover, since there might be a large fluctuations of companies, are close to the division line between the top and bottom 20%. We therefore limit the turnover by not dropping the stock from our portfolio if it just moves to the adjacent portfolio category.

```{r Finding from 1 and 3, echo=FALSE}

# Define function to calculate the sharpe ratio
Sharpe_ratio = function(x, annualized = FALSE){
  if(annualized){
    multiplier <- 12
  } else{
    multiplier <- 1
  }
  mu <- mean(x * multiplier)
  sd <- sd(x) * sqrt(multiplier)
  return(mu/sd)
}

# Initializes table for output
summary3 <- matrix(NA, ncol = 3, nrow = 2)

# Adds row names
rownames(summary3) <- c("Standard long-short portfolio","Our long-short portfolio")

# Add the data
summary3[,1] <- c(Sharpe_ratio(long_short_portfolio$long_short, annualized = FALSE), Sharpe_ratio(our_mom_long_short_portfolio$long_short, annualized = FALSE))
  summary3[,2] <- c(mean(long_short_portfolio$long_short), mean(our_mom_long_short_portfolio$long_short))
summary3[,3] <- c(turnover_mom, our_mom_turnover)

# Prints the table
summary3 %>%
  knitr::kable(booktabs = T, 
               digits = 4, 
               col.names = c("Sharpe ratio", "Estimated excess return", "Turnover"),
               caption = "Sharpe ratio") %>% 
  kable_paper("hover", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position")


```

We see that our suggested strategy has a better sharpe ratio, so a better return proportional to the amount of risk taken. The positive excess return of 0.47% compared to 0.75% suggests, that we are able to catch a good part of the momentum premium, but with a turnover that is about 25% smaller while also taking on less risk. We therefore conclude that the strategy works decently for the assigned purpose.

# Exam part 2
In part 2 of this report we will use a dataset which consists of 252 monthly observations for $N=8$ different US-listed stocks identified by their permno which is a unique company identifier. The permno for the stocks used are: 10026, 10032, 10044, 10104, 10200, 10232, 10252 and 10397. The whole dataset includes monthly observations from "2000-01-01" to "2020-12-01". All the portfolio weights from our strategies will be found by using the data up until (and including) 2015, where the last 5 years will then be used to test the out-of-sample returns for these strategies. For each month-permno observation, the dataset contains the following variables: ret_excess is the net excess return for each month. mkt_excess, smb and hml are the market excess returns, the returns of the small-minus-big portfolio and the high-minus-low book-to-market ratio portfolio returns from Kenneth Frenchâ€™s homepage. beta is the estimated CAPM beta of the stock, measured at the beginning of month t, size is a measure of market capitalization of the stock at the beginning of month t and bm is the book-to-market ratio of the stock, measured at the beginning of month t. The columns beta, size and bm are standardized such that the monthly cross-sectional average is zero and the monthly cross-sectional standard deviation is one.


## Problem 1
We will now try to estimate the Fama French 3-factor model:
\begin{equation*}
    r_{i,t} = \alpha_i + \beta_i^\text{M} r_{m,t} + \beta_i^{\text{SMB}} r_{smb,t} + \beta_i^\text{HML} r_{hml,t} + \epsilon_{i,t}
\end{equation*}
This will be done by making a linear regression of the excess return for each stock on each of the three Fama French parameters. This results in the following table:

```{r, echo=FALSE}

parameter_estimates <- US_Stocks %>%
  group_by(permno) %>%
  summarise(alpha_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            alpha_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,2],
            beta_m_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[2,1],
            beta_m_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            beta_smb_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[3,1],
            beta_smb_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1],
            beta_hml_estimate = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[4,1],
            beta_hml_sd = summary(lm(ret_excess ~ mkt_excess + smb + hml))$coefficients[1,1]) 

parameter_estimates %>%
  knitr::kable(booktabs = T, digits = 4, col.names = c("Permno", "Estimate", "sd", "Estimate", "sd", "Estimate", "sd", "Estimate", "sd"), caption = "Fama French 3-factor estimates for the 8 stocks (estimated from 2000 to 2015)", align = "c") %>%
  add_header_above(c(" " = 1, "alpha" = 2, "beta M" = 2, "beta SMB" = 2, "beta HML" = 2)) %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")


```

Table 9 provides the empirical estimates for the Fama French 3-factor model for the 8 selected US stocks. The three $\beta$-estimates show the correlation between the return for stock $i$ and market return along with the two Fama French portfolio returns (SMB and HML). Here we for example see that the stock with permno 10200 has a very large negative correlation with the HML portfolio wheres the stock with permno 10252 has a fairly large positive correlation with the portfolio. For the SMB portfolio, we notice that all the stocks have a positive correlation with this, which indicates that the selected stocks probably have a small market cap. Permno 10200 (which is Repligen Corporation) has $\beta_i^{SMB}=1.9845$. This makes sense since the company had an average market cap of only \$230 million USD in the estimated period. From the $\beta_i^{M}$-estimates we can also see that all the stocks have a positive correlation with the market. Lastly we also see that the $\alpha_i$-estimates are all very low compared to the $\beta$-estimates which indicates that most of the excess return information for the stocks can be explained by the Fama French 3-factor model. By looking at all the standard deviations for the estimates, we see that they are all very low compared to the estimators, indicating that the confidence intervals for the estimates are very low.

We will now derive the model-implied expected gross excess return $\hat{\boldsymbol{\mu}}^{FF}$ and the model-implied variance-covariance matrix $\hat{\boldsymbol{\Sigma}}^{FF}$. A bold symbol signifies that it is a vector or a matrix. We start by deriving $\hat{\boldsymbol{\mu}}^{FF}$, which is a vector consisting of the model-implied expected gross excess return for each of the 8 stocks, where we use that $E\left[\epsilon_{i,t}\right]=0$:
\begin{align*}
    \hat{\boldsymbol{\mu}}^{FF} = E\left[\boldsymbol{r}_{t}\right] = \frac{1}{N}\sum_{t=1}^N\left(\boldsymbol{\alpha} + \boldsymbol{\beta}^\text{M} \boldsymbol{r}_{m,t} + \boldsymbol{\beta}^{\text{SMB}} \boldsymbol{r}_{smb,t} + \boldsymbol{\beta}^\text{HML} \boldsymbol{r}_{hml,t}\right)
\end{align*}
In order to derive $\hat{\boldsymbol{\Sigma}}^{FF}$ we use that the covariance of an asset with itself is just the variance. All the entries in $\hat{\boldsymbol{\Sigma}}^{FF}$ can therefore be calculated as follows, where we use that $Cov(r_{k,t}, \epsilon_{i,t}) = 0$ for all factors $k$:
\begin{align*}
    Cov\left(r_i,r_j\right) &= E\left[r_i r_j\right] - E\left[r_i\right]E\left[r_j\right] = \frac{1}{N}\sum_{t=1}^N\left(r_i r_j\right) - \hat{\mu}_i^{FF}\hat{\mu}_j^{FF}
\end{align*}
Since the returns are estimated from the Fama French 3-factor model, it is clear that the correlation of the returns is determined by a mixture of the $\beta$-estimates and the Fama French market- and portfolio returns. If two stocks for example have a large positive $\beta^M$-value, and the $r_{m,t}$ is large enough to play a significant role, then both of these stocks will have a return moving in the same direction.



```{r}
# Compute the model-implied returns
compute_fama_french_returns <- function(parameter_estimates, stock_data){
  parameter_estimates <- parameter_estimates %>% select("alpha_estimate", "beta_m_estimate", "beta_smb_estimate", "beta_hml_estimate")
  stock_data <- stock_data %>% select("permno", "month", "mkt_excess", "smb", "hml")
  
  months <- unique(stock_data$month)
  N <- length(months)
  returns <- matrix(NA, ncol = length(unique(stock_data$permno)), nrow = N)
  colnames(returns) <- unique(stock_data$permno)
  
  for(i in (1:N)){
    stocks_monthly <- stock_data %>% filter(month == months[i])
    returns[i,] <- parameter_estimates$alpha_estimate + parameter_estimates$beta_m_estimate * as.numeric(stocks_monthly$mkt_excess) + parameter_estimates$beta_smb_estimate * as.numeric(stocks_monthly$smb) + parameter_estimates$beta_hml_estimate * as.numeric(stocks_monthly$hml)
  }
  returns
}

# Compute the model-implied expected gross excess return (mu_hat)
compute_fama_french_mu <- function(parameter_estimates, stock_data){
  returns <- compute_fama_french_returns(parameter_estimates, stock_data)
  colMeans(returns)
}




# Compute the model-implied variance covariance matrix (Sigma_hat)
compute_fama_french_sigma <- function(parameter_estimates, stock_data){
  
  mu <- compute_fama_french_mu(parameter_estimates, stock_data)

  stock_data <- stock_data %>% 
    ungroup() %>%
    select("permno", "month", "ret_excess", "mkt_excess", "smb", "hml") %>%
    left_join(parameter_estimates, by = "permno") %>%
    mutate(FF_return = ret_excess - (alpha_estimate + beta_m_estimate * mkt_excess + beta_smb_estimate * smb + beta_hml_estimate * hml)) 
  
  N <- length(unique(stock_data$month))
  
  stocks <- unique(parameter_estimates$permno)
  
  Sigma <- matrix(NA, ncol = length(stocks), nrow = length(stocks))
  colnames(Sigma) <- stocks
  rownames(Sigma) <- stocks
  
  for(i in 1:length(stocks)){
    stock_i <- stock_data %>% filter(permno == stocks[i])
    j <- i
    while(j <= length(stocks)){
      stock_j <- stock_data %>% filter(permno == stocks[j])
      Sigma[i,j] <- Sigma[j,i] <- as.numeric(sum(stock_i$FF_return * stock_j$FF_return)/N - mu[i]*mu[j])
      j <- j + 1
    }
  }
  Sigma
}

# Function that computes the optimal weights
compute_mean_variance_portfolio_weights <- function(mu, Sigma, gamma = gamma_default){
  N <- ncol(Sigma)
  iota <- rep(1, N)

  # Invert Sigma 
  Sigma_inv <- solve(Sigma) 
  
  # Calculates the optimal portfolio weights
  w_mvp <- Sigma_inv %*% iota
  w_mvp <- w_mvp / sum(w_mvp)
  w_opt <- w_mvp  + 1/gamma * (Sigma_inv - w_mvp %*% t(iota) %*% Sigma_inv) %*% mu
  return(w_opt)
}


```


We now use these parameter estimates to report the computed implied mean-variance efficient portfolio weight for an investor with risk aversion $\gamma = 4$, defined by the solution to the standard Markowitz problem, which is:
$$\boldsymbol{\omega}^{*} = \frac{1}{\gamma}\left(\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1} - \frac{1}{\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}}\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}\right)\hat{\boldsymbol{\mu}}^{FF} + \frac{1}{\boldsymbol{\iota}^{\prime}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}}\left(\hat{\boldsymbol{\Sigma}}^{FF}\right)^{-1}\boldsymbol{\iota}$$
By using this, we get that the following implied mean-variance portfolio weights:

```{r, echo=FALSE}
mu <- compute_fama_french_mu(parameter_estimates, US_Stocks)
Sigma <- compute_fama_french_sigma(parameter_estimates, US_Stocks)

portfolio_weights <- t(compute_mean_variance_portfolio_weights(mu, Sigma))
rownames(portfolio_weights) <- "Weights"

portfolio_weights %>%
  knitr::kable(booktabs = T, 
               digits = 4, 
               caption = "Mean-variance efficient portfolio weights using $\\hat{\\boldsymbol{\\mu}}^{FF}$ and $\\hat{\\boldsymbol{\\Sigma}}^{FF}$") %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")
```


## Problem 2
Instead of estimating one weight for each stock for the different points in time, we instead estimate weights using a vector of parameters, $\boldsymbol{\theta}$, and some chosen firm characteristics. $\boldsymbol{\theta}$ applies to all stocks through time. We define portofolio weights as a function of the benchmark portfolio ($\bar{\omega}_{i,t}$), $\boldsymbol{\theta}$ and stock characteristics ($\hat{\boldsymbol{x}}_{i,t}$). 
$$\omega_{i,t}=\bar\omega_{i,t}+\frac{1}{N_t}\boldsymbol{\theta}^{\prime}\hat{\boldsymbol{x}}_{i,t}$$
To estimate $\boldsymbol{\theta}$ we maximize the linear policy case function:
$$\max\limits_{\boldsymbol{\theta}} \frac{1}{N}\displaystyle\sum_{i=0}^{T-1} \bigg(\displaystyle\sum_{i=1}^{N_t}\bigg (\bar\omega_{i,t}+\frac{1}{N_t}\boldsymbol{\theta}^{\prime}\hat{\boldsymbol{x}}_{i,t} \bigg) r_{i,t+1} \bigg)$$

The most important aspect of the coefficient $\boldsymbol{\theta}$ is that the parameterization is constant across assets through time. Because we have a constant coefficient across assets the weight in the portfolio for each stock will depend on the characteristics of the stock and not on the stocks historic returns. This implies that two stocks with identical characteristics will have identical weights despite them having widely different historic returns.

To estimate $\hat{\boldsymbol{\theta}}$ we program a series of functions to determine the parametric portfolio given $\boldsymbol{x}_{i,t}$ and ${\theta}$. We then implement a function to determine the portfolio's gross return, calculate its certainty equivalent and use the *optim* function in R to do numerical optimization of the certainty equivalent by adjusting $\hat{\boldsymbol{\theta}}$. We define our initial $\hat{\boldsymbol{\theta}}$ as $[\begin{matrix} 1 & 1 & 1 \end{matrix}]^{\prime}$.



```{r, echo=FALSE}

#Define the number of stocks
N <- US_Stocks$permno %>% 
  unique() %>% 
  length

#Define an initial guess of theta
theta <- rep(1, 3)

#Define function to compute the portfolio weights
compute_parametric_portfolio_weights <- function(theta,  data) {
  data %>%
  group_by(month) %>%
  mutate(
    characteristic_tilt = beta*theta[1] + size*theta[2] + bm*theta[3]
    )%>%
  mutate(
    # Definition of benchmark weight
    weight_benchmark = 1/N,
    # Parametric portfolio weights
    weight_tilt = weight_benchmark + characteristic_tilt/N
    ) %>%
  ungroup()
}

# Define the certainty equivalent function to be the utility that must be maximized
utility_function <- function(r, gamma = gamma_default) { 
  mean(r)-gamma/2*var(r)
}

# Define a function to evaluate the portfolio return by generating af vector of monthly gross returns and returning it
evaluate_portfolio <- function(weights_parametric_portfolio){
 tmp<-weights_parametric_portfolio %>% 
    mutate(return_x_w = ret_excess * weight_tilt) %>%
    group_by(month) %>%
    summarise(across(return_x_w, sum)) %>%
    mutate(Rp = return_x_w+1)
 
  return(tmp$Rp)
}

# Function that gathers the framework and allows "optim" to maximize the utility by adjusting theta 
compute_objective_function <- function(theta, data) {
  
  #Use the compute_parametric_portfolio_weights function to calculate the portfolio weights given theta
  processed_data <- compute_parametric_portfolio_weights(theta,data)
  
  # Use the evaluate_portfolio function to generate the gross returns for the utility function and pipe this vector to the utility function
  objective_function <- evaluate_portfolio(processed_data) %>% utility_function()
  
  #Return that negative of the objective as optim minimizes per default
  return(-objective_function)
}

# Run optim to determine theta_hat
optimal_theta <- optim(
  par = theta, 
  compute_objective_function,
  data = Out_Of_Sample
)

# Extracting optimal theta values (which we just found)
theta_hat <- optimal_theta$par 

# Creating table to store and print theta_hat values
theta_hat_table <- matrix(NA, ncol = 3, nrow = 1)

theta_hat_table[1,] <- as.vector(theta_hat)

rownames(theta_hat_table) <- "Theta hat"

# Printing a table with the theta_hat values
theta_hat_table %>%
  knitr::kable(booktabs = T, 
               digits = 4,
               col.names = c("Beta", "Size", "BM"),
               caption = "Optimal $\\hat{\\boldsymbol{\\theta}}$ estimated on data up until december 31st 2015") %>%
  kable_paper("hover", full_width = F) %>%
  kable_styling(latex_options = "HOLD_position")

# Computing optimal weights for last period of the sample
w_pp <- compute_parametric_portfolio_weights(theta_hat, US_Stocks %>% 
                                              filter(month == max(Sub_US_Stocks$month))) %>% 
  pull(weight_tilt)

# Creating table to store and print optimal weights
w_pp_table <- matrix(NA, ncol = length(unique(Sub_US_Stocks$permno)), nrow = 1)

w_pp_table[1,] <- as.vector(w_pp)
rownames(w_pp_table) <- "Weights"

# Printing a table with the optimal weights for last period of the sample
w_pp_table %>%
  knitr::kable(booktabs = T, 
               digits = 4,
               col.names = unique(Sub_US_Stocks$permno),
               caption = "Optimal parametric portfolio weights computed for december 2015 given $\\hat{\\boldsymbol{\\theta}}$") %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(latex_options = "HOLD_position")

```


## Problem 3

```{r}
# Defining af function which computes the efficient portfolio weights defined in problem 3
compute_efficient_weight <- function(Sigma, mu, gamma = gamma_default){
  # Creating a vector of ones
  iota <- rep(1, ncol(Sigma))
  
  Sigma_inverse <- solve(Sigma)
  
  # Computing optimal Markowitz weights (equation derived in problem 1)
  w_mvp <- Sigma_inverse %*% iota
  w_mvp <- as.vector(w_mvp / sum(w_mvp))
  w_opt <- w_mvp  + 1/gamma * (Sigma_inverse - 1 / sum(Sigma_inverse) * Sigma_inverse %*% iota %*% t(iota) %*% Sigma_inverse) %*% mu
  return(as.vector(w_opt))
}

# Creating the returns matrix (columns = stocks and rows = months)
returns_matrix <- Sub_US_Stocks %>% select(permno, month, ret_excess) %>%
  pivot_wider(
    names_from = permno,
    values_from = ret_excess) %>% 
  select(-month)

# Finding mu_tilde
mu_tilde <- colMeans(returns_matrix)

# Finding sigma_tilde
sigma_tilde <- cov(returns_matrix)
 
# Creating the naive (equal-weighted) portfolio weights
naive <- 1/ncol(sigma_tilde) * rep(1, ncol(sigma_tilde))

# Computing the efficient portfolio weights
efficient <- compute_efficient_weight(sigma_tilde, mu_tilde)

# Computing the total return for each stock over the out-of-sample period
excess_return <- Out_Of_Sample %>% 
  select(permno, ret_excess) %>% 
  group_by(permno) %>% 
  summarise(across(ret_excess, sum)) %>%
  pull(ret_excess)

# Initializes table for output
strategies_returns <- matrix(NA, ncol = 4, nrow = 2)

# Adds row names
rownames(strategies_returns) <- c("Total return","Annual sharpe ratio")

# Add the data
strategies_returns[1,] <- c(sum(excess_return * portfolio_weights), sum(excess_return * w_pp_table), sum(excess_return * efficient), sum(excess_return * naive))
strategies_returns[2,] <- c(Sharpe_ratio(excess_return * portfolio_weights, annualized = TRUE), Sharpe_ratio(excess_return * w_pp_table, annualized = TRUE), Sharpe_ratio(excess_return * efficient, annualized = TRUE), Sharpe_ratio(excess_return * naive, annualized = TRUE))

# Prints the table
strategies_returns %>%
  knitr::kable(booktabs = T,
               digits = 4,
               col.names = c("Fama French", "Parametric", "Efficient", "Naive"),
               caption = "Sharpe ratio") %>%
  kable_paper("hover", full_width = F) %>%
  kable_styling(latex_options = "HOLD_position")
 
```

The different strategies show us that Fama French has the highest total return, but its sharp ratio is only the second highest. The highest sharpe ratio comes from the Naive portfolio, which has the second highest total return. This shows us that the best portfolio is the Naive portfolio compared to the amount of risk we have taken. With back-testing strategies, a problem with the estimation can come when we use a very complex model on a dataset which is too small. As our estimation will try to fit more of the data, this can lead to overfitting. A shortfall for this implementation is that we create a portfolio which should hold for 5 years without rebalancing. This is a hard task, since we try to predict so far into the future based on the historical data.

The Parametric portfolio strategy in a high-dimensional asset universe will be affected if it needs more characteristics as parameters, as this will make it heavier to optimize. So we expect it to perform better if we add more characteristics, but it will also make the calculation heavier and therefore take more time. The Naive portfolio will, with a certain number of assets, eliminate the diversifiable risk, but still, leave the systematic risk. An efficient portfolio will in this kind of universe have problems if the time horizon is to small, as it needs a long time horizon to calculate the covariance matrix. Fama French will perform well if it is given a time horizon that is long enough, as the investor has to ride out underperformance and volatility that could occur in the short term.  

From the chosen portfolio weights we have acquired from all 4 methods our assessment is that the Efficient portfolio will have the largest turnover and therefore the largest transaction costs. The Fama French and the Parametric portfolios will have about the same turnover and the naive portfolio will by far have the lowest turnover as it only has to be adjusted marginally to compensate for the effect of the returns.




